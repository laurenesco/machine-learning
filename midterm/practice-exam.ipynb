{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea8fa8e-48b5-42e0-9dc5-326f9cd82997",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdbb9a-987e-4139-9bae-3396e6534385",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "Devise the update rule for minimizing $f(x)=(max⁡(0,x)−\\frac{1}{2})^2$ using gradient descent. Roughly, when will gradient descent succeed or fail (based on where you start and step size)?\n",
    "\n",
    "---\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "The gradient descent update rule for a function is derived by:\n",
    "1. Finding the loss function for a point $x_i$\n",
    "2. Taking the derivate with respect to the model parameters to compute the gradient of the loss function, or $\\nabla L(w)$\n",
    "3. Plugging these values into the update rule to form:\n",
    "\n",
    "$$ w_{\\text{new}} = w_{\\text{old}} - \\eta \\nabla L(w_{\\text{old}}) $$\n",
    "\n",
    "##### **Finding Loss Function**\n",
    "   \n",
    "Since we are given $f(x)=(max⁡(0,x)−\\frac{1}{2})^2$, we will assume this is the loss function to perform gradient descent on.\n",
    "\n",
    "##### **Taking the derivatives**\n",
    "\n",
    "Since the function contains a max() function, we will compute the gradient for the max being 0 and being $x$.\n",
    "\n",
    "- For $f(x)=(0−\\frac{1}{2})^2$:\n",
    "$$ \\frac{d}{dx}((0−\\frac{1}{2})^2) = 0 $$\n",
    "- For $f(x)=(x−\\frac{1}{2})^2$:\n",
    "$$ \\frac{d}{dx}((x−\\frac{1}{2})^2) = 2(x-\\frac{1}{2})\\cdot \\frac{d}{dx}(x-\\frac{1}{2})$$\n",
    "$$ = 2(x-\\frac{1}{2})\\cdot 1 $$\n",
    "$$ = 2(x-\\frac{1}{2}) $$\n",
    "\n",
    "##### **Plugging it all in**\n",
    "\n",
    "Plugging in the above results, we have that when $max(0,x) = 0$:\n",
    "\n",
    "$$ w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot 0 $$\n",
    "\n",
    "And when $max(0,x) = x$:\n",
    "\n",
    "$$ w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot 2(x-\\frac{1}{2}) $$\n",
    "\n",
    "##### **Where will Gradient Descent Succeed and/or Fail**\n",
    "\n",
    "Gradient descent can fail for several reasons:\n",
    "- Local minima (non-convex function) may cause the algorithm to not be able to find the global minimum, or lowest loss, for the function\n",
    "- Too large of a step size parameter may lead to the algorithm oscillating around the minimum or even diverging\n",
    "\n",
    "We can use the second derivative test to check if the function is convex:\n",
    "\n",
    "$$ \\frac{d}{dx}(2(x-\\frac{1}{2})) = 2 $$\n",
    "$$ \\frac{d}{dx}(2(0-\\frac{1}{2})) = 0 $$\n",
    "\n",
    "In both cases the second derivate is non-negative, so the function is convex everywhere.\n",
    "\n",
    "And we can find the minimum of the function by setting the derivate equal to 0:\n",
    "\n",
    "$$ 2(x-\\frac{1}{2}) = 0 $$\n",
    "$$ x = \\frac{1}{2} $$\n",
    "\n",
    "So the minimum is $\\frac{1}{2}$.\n",
    "\n",
    "Thus, in this case the algorithm will fail if $x \\le 0$, as no updates will occur. It will also fail if using too large of a step size which could overshoot the minimum. So if we start with $x > 0$ and a reasonable step size, it will succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd61297-741b-46de-9aca-ab87f260ca4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b4f30-70ca-4264-a324-c8ac798c8031",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "Given a data set $A$, under what circumstances will its projection onto its principal components equal its projection onto its right singular vectors and left singular vectors\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "PCA works really on a data set of points, but first requires organizing it into a matrix $A$. The question emphasizes that there are two ways of doing this:\n",
    "\n",
    "The points are rows. In this case the principal components are the right singular vectors, the eigenvectors of $A^⊤A$.\n",
    "\n",
    "The points are columns. In this case the principal components are the left singular vectors, the eigenvectors of $AA^⊤$. This is actually analogous to (1) except effectively with $A^⊤$ and $A$ switched.\n",
    "\n",
    "In either case, a point equaling its projection onto the first $k$ principal components means that the points in your data set are really $k$-dimensional – they are all linear combinations of just the $k$ principal components. So that’s often something useful to know about a data set.\n",
    "\n",
    "Brief review of SVD and PCA:\n",
    "\n",
    "PCA computes the eigen-decomposition of a covariance matrix $A^TA$, which is by definition symmetric and therefore (spectral theorem) can be written as the product of $QΣQ^T$ where $Q$ is a orthogonal matrix (square matrix with orthonormal rows and vectors) and $Σ$ is diagonal. The entries of $Σ$ are the eigenvalues and the columns/rows of $Q$/$Q^T$ are the eigenvectors of the covariance matrix. The covariance matrix is square ($n x n$), as is $Q$ and $Σ$.\n",
    "\n",
    "SVD on the other hand decomposes any matrix (does not have to be square, symmetric, etc.) into $USV^T$, where $U$ and $V^T$ are square, orthogonal matrices; however, in contrast to the eigen-decomposition above, if working with $A$, $U$ will be $m x m$, $V^T$ will be $n x n$, and $S$ will be $m x n$.\n",
    "\n",
    "To start the problem assume $A$ is $m x n$, where $m$ is the number of data samples and $n$ is the feature dimension. That is, each row is a sample represented by $n$ values.\n",
    "\n",
    "Compute the SVD of A=USVTA=USVT and then perform PCA over A by computing the eigen-decomposition of the covariance matrix:\n",
    "\n",
    "$A^TA=(USV^T)^T(USVT^)=(VSU^T)(USV^T)=VS^2V^T$, which implies the columns/rows of $V/V^T$ are the eigenvectors of $A$ as well as the right singular vectors of $A$.\n",
    "\n",
    "Now consider the case when $A$ is structured as rows of features and columns of samples. That is, $A$ is $n \\times m$. Then the covariance matrix of $A=AA^T$ and the SVD of $A=(USV^T)(VSU^T)=(US^2U^T)$. Therefore, in this case, the eigenvectors of the covariance matrix are the left singular vectors of the data matrix.\n",
    "\n",
    "In conclusion, the condition under which the right singular vectors of a data matrix AA are also the principal directions is AA being structured as rows of samples. On the other hand, when AA is columns of samples then the left singular vectors of AA and the principal directions.\n",
    "\n",
    "A couple of other useful notes previous students discovered about PCA and SVD:\n",
    "\n",
    "The eigen-decomposition of a symmetric expresses how a matrix scales (but does not rotate) a specific set of vectors. First you apply an invertible, linear transformation by multiplying by $Q^T$, then scales via $Σ$, finally inverting the original transformation.\n",
    "\n",
    "SVD is a rotation, followed by scaling, followed by rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573ceb4-908d-4e0c-8877-80a9ce2f4abd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7afc82-cc6d-4ab7-8fd9-ef50f1911899",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "Let $S$ be a set of documents and let $T$ be a set of terms. Suppose that $C$ is a binary term-document incidence matrix (so entry ($i$,$j$) is a 1 if term $i$ appears in document $j$ and 0 otherwise). What do the entries of $C^TC$ represent?\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "If $C$ is a binary term-document incidence matrix, and $S$ is a set of documents and $T$ is a set of terms, $C^TC$ will provide information about the similarity between the terms and documents.\n",
    "\n",
    "In this case: The dimensions of $C^TC$ is num docs by num docs, so the element at $(i,j)$ is the number of shared terms between doc-$i$ and doc-$j$. Also for the diagonal elements like $(i,i)$ it means the total number of terms in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff8b1a-b189-42ee-b3f8-b82e7536a39d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41abf3d-d34c-4583-9d9b-c7ca08ff801b",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "How did we derive the equations for simple linear regression from class?\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "**The goal** is to find a vector $w \\in \\mathbf{R}^n$ that minimizes $||X\\cdot w-y||^2_2$\n",
    "\n",
    "Example, given: \n",
    "\n",
    "$$ x^1 = x^1_1, \\dots , x^1_n \\;\\;\\;\\; y^1 $$\n",
    "\n",
    "Then: \n",
    "\n",
    "$$ (y-(x^1_1 w_1 + \\dots +x^1_n w_n))^2 $$\n",
    "\n",
    "#### **Formal Problem Statement**\n",
    "\n",
    "$$ \\underset{w}{\\min} ||Xw-y||^2_2 $$\n",
    "\n",
    "#### **How to Find w**\n",
    "\n",
    "Let's find $w$ by using geometric concepts. $Xw$ is a vector in the span of the columns of $X$. The point $y \\in \\mathbf{r}^n$ is not necessarily in the span of $X$.\n",
    "\n",
    "What point should we pick in the span of $X$ to best approximate $y$, geometrically speaking? We should take the orthogonal projection of $y$ down to the span of $X$, and that is the optimal point. We will call this point $Xw$, and that is the point we should choose.\n",
    "\n",
    "The vector $y-Xw$ line from the point $y$ to the point $Xw$, which is orthogonal to  $X$.\n",
    "\n",
    "Now we can take the vector $y-Xw$ and, since it is orthogonal to $X$, do the following:\n",
    "\n",
    "$$ X^T\\cdot (y-Xw) = 0 $$\n",
    "$$ X^Ty-X^TXw = 0 $$\n",
    "$$ X^Ty = X^TXw $$\n",
    "$$ (X^TX)^{-1}X^Ty = w $$\n",
    "\n",
    "Thus, we have solved for $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5f118-d120-479b-b1e8-3d6cb6b02bcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dca23f-f60d-4b42-8c6b-fb4434f3e804",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "Why can you assume without loss of generality that a mistake-bounded learner only updates its state when it makes a mistake?\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "It can be shown that LL is also a mistake-bounded learner.\n",
    "\n",
    "The above reasoning shows that for every L′L′, we can always construct a LL that only updates its state when making a mistake. Therefore, without losing generality, we can always assume a mistake-bounded learner only updates its state when making a mistake.\n",
    "\n",
    "[Original explanation]\n",
    "\n",
    "you can always change the ordering so that it makes mistake at the very beginning of the TT (the mistake bound) examples and stop making mistake. In this way, the learner who may change at correct label does not improve the mistake bound TT.\n",
    "\n",
    "Detail: Suppose the mistake bound is TT for a learner LL that only make change at mistake, we can safely reorder the list of training examples so that the TT examples come in the first place. In this situation, the learner LL will perform the same thing and make mistakes at the first TT training examples. (since before reordering, LL does not update in correct training examples). Consider any other learner L′L′ that may change in correct label, in the re-ordering case, it will behave exactly like LL so the mistake bound is still at least TT, which make no improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f1374-ab85-49d0-b946-a9ca8787fe79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f3b356-ec42-404e-ab41-edebabfbc2ba",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "You are given a data set with $m$ points and an algorithm that satisfies the weak-learning condition (it always outputs a classifier with accuracy 60%). Each classifier output by the weak-learning algorithm can be encoded using two bits. How can you construct a classifier that can be described by less than $m$ bits and is correct on every data point in the data set (you may assume $m$ is very large). What is the size of your final classifier?\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "The idea is to use boosting as follows. In this case we want a classifier with training error 0. But because the only possible values for training error are $1,(m−1)/m,...,1/m,0$ (since it is 0-1 loss and there are only $m$ points), this is equivalent to achieving training error $<1/m$. Now recall that the training error of the AdaBoost hypothesis after $T$ rounds is at most $exp⁡(−2γ^2T)$. Here $γ=0.1$ since we have a 0.6-accurate weak learner. Thus $T$ only needs to be $Θ(log⁡m)$ for the training error to be less than $1/m$, and hence to be 0. After this many rounds, the final classifier classifies the entire training set correctly. And recall again that this final classifier is just the majority of $T$ different classifiers, which each take two bits to describe. Thus we just need $Θ(logm)$ bits to describe this classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94170f71-3494-48ac-85cf-c1c63bebf9e9",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63867fe8-6d78-4686-a5b3-07bc85c242d3",
   "metadata": {},
   "source": [
    "### **Question**\n",
    "\n",
    "How can you compare Markov’s inequality, Chebyshev’s inequality, and the Chernoff bound?\n",
    "\n",
    "### **Answer**\n",
    "\n",
    "Roughly speaking, Markov is the weakest bound here, Chebyshev's a little stronger, and the Chernoff bound is the strongest. This question is a little broad, but it's important to familiarize yourself with exactly when each inequality is applicable. For instance, sometimes Chernoff might not be applicable and Chebyshev might be the best you can do. In particular:\n",
    "\n",
    "Markov applies to nonnegative random variables\n",
    "\n",
    "Chebyshev applies to random variables for which you have a variance bound\n",
    "\n",
    "Chernoff applies to sums of i.i.d. random variables (in fact generally indicator variables)\n",
    "\n",
    "At a high level, all three bounds describe the probability that a random variable falls far from its expectation. They differ in the assumptions made about the underlying distribution.\n",
    "\n",
    "Markov\n",
    "\n",
    "A non-negative random variable cannot be much larger than its mean very often. This bound depends only on the expected value of the random variable and that XX is non-negative. No other assumptions made.\n",
    "\n",
    "∀X≥0, P(X≥λ)≤E(X)λ\n",
    "∀X≥0, P(X≥λ)≤λE(X)​\n",
    "\n",
    "Proof: if you define random variable ZZ to be 11 if X≥λX≥λ and 00 otherwise then it's easy to see:\n",
    "\n",
    "λZ≤X  ⟹  E(λZ)≤E(X)\n",
    "λZ≤X⟹E(λZ)≤E(X)\n",
    "\n",
    "E(λZ)=λE(Z)=λ(1P(X≥λ)+0P(X<λ))=λP(X≥λ)≤E(X)  ⟹  P(X≥λ)≤E(X)λ\n",
    "E(λZ)=λE(Z)=λ(1P(X≥λ)+0P(X<λ))=λP(X≥λ)≤E(X)⟹P(X≥λ)≤λE(X)​\n",
    "\n",
    "Chebyshev\n",
    "\n",
    "The probability a random variable is more than kk standard deviations from the mean is no more than 1k2k21​. This bound assumes XX has non-zero, finite variance.\n",
    "\n",
    "P(∣X−E(X)∣≥kσ)<1k2\n",
    "P(∣X−E(X)∣≥kσ)<k21​\n",
    "\n",
    "Proof: Let XX be a random variable over real numbers and Y=(X−E(X))2Y=(X−E(X))2. Note, YY is now a non-negative random variable. By Markov's rule we know:\n",
    "\n",
    "P(Y≥λ)≤E(Y)λ  ⟹  P((X−E(X))2≥λ)≤E(X−E(X))2)λ=σ2λ\n",
    "P(Y≥λ)≤λE(Y)​⟹P((X−E(X))2≥λ)≤λE(X−E(X))2)​=λσ2​\n",
    "\n",
    "Set λ=σ2k2λ=σ2k2 and you have:\n",
    "\n",
    "P((X−E(X))2≥σ2k2)=P(∣X−E(X)∣≥kσ)≤σ2σ2k2=1k2\n",
    "P((X−E(X))2≥σ2k2)=P(∣X−E(X)∣≥kσ)≤σ2k2σ2​=k21​\n",
    "\n",
    "Chernoff Bounds\n",
    "\n",
    "I found it hard to state this succinctly, but similar to the above bounds the probability of a random variable being far from the mean.\n",
    "\n",
    "Follows from the application of the Markov bound to random variable Y=etXY=etX. Specifically, it says:\n",
    "\n",
    "P(X≥λ)=P(Y≥etλ)=P(etX≥etλ)≤E(Y)etλ=E(etX)etλ\n",
    "P(X≥λ)=P(Y≥etλ)=P(etX≥etλ)≤etλE(Y)​=etλE(etX)​\n",
    "\n",
    "This works because Y≥0Y≥0.\n",
    "\n",
    "There is a special case I've seen mentioned which is when XX is the sum of mm independent Bernouli RV's, X1,..,XmX1​,..,Xm​ where ∀i∀i, P(Xi=1)=piP(Xi​=1)=pi​. Defining p=mp0p=mp0​ and h(δ)=(1+δ)log(1+δ)−δh(δ)=(1+δ)log(1+δ)−δ then\n",
    "\n",
    "P(X>(1+δ)p)≤e−h(δ)p\n",
    "P(X>(1+δ)p)≤e−h(δ)p\n",
    "\n",
    "More on this in textbook appendix B.3 including the case for X<(1+δ)pX<(1+δ)p."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
