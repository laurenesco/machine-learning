{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be158dc-a876-43cb-9c39-279dd11cea45",
   "metadata": {},
   "source": [
    "# Kernel Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41c711-1504-4cd0-93a3-aa8a6963a859",
   "metadata": {},
   "source": [
    "## ***Vocabulary***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ceb54-7137-431e-8ae1-1053d0f2bcbe",
   "metadata": {},
   "source": [
    "**kernel function**\n",
    "- a two variable function that is symmetric: $K(x, x') = K(x', x)$\n",
    "\n",
    "**basis function**\n",
    "- A basis function is a mathematical function used to transform input data into a new representation, typically in a higher-dimensional space, to help capture complex patterns or relationships.\n",
    "\n",
    "**interpolate**\n",
    "- the ability to exactly reporoduce the observed values of the dataset at the training points\n",
    "\n",
    "**positive semi-definite**\n",
    "- a square matrix $K$ is postivie semi-definite if\n",
    "1. it is symmetric ($K = K^T$)\n",
    "2. for any non-zero vectore $z$, the quadratic form $z^TKz \\ge 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc47029-8dd1-4934-8f85-9487837b1e2c",
   "metadata": {},
   "source": [
    "# Lecture Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eb618-a347-4dd5-bb64-a4efac8cacf4",
   "metadata": {},
   "source": [
    "## ***The Kernel Method***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc401538-1983-40c0-b231-f535e625a1cf",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc46621-ff82-4b2f-abac-5be1958c13b4",
   "metadata": {},
   "source": [
    "#### **What is a Kernel Method**\n",
    "\n",
    "The kernel method is a very important class of algorithms and methods for constructing very flexible, nonlinear functional approximations in machine learning. They achieve this by mapping data into higher dimensional spaces.\n",
    "\n",
    "#### **Reviewing Supervised Learning**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.6.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "We can see that in supervised learning, the three main steps are:\n",
    "1. Decide a function class $\\mathcal {F}$, which cannot be too large (overfitting), but must be large enough to consider the complexities of the data.\n",
    "2. Define a loss function for $\\mathcal{f} \\in \\mathcal{F}$\n",
    "3. Solve the optimization problem of finding the lowest loss for each $\\mathcal {f} \\in \\mathcal{F}$.\n",
    "\n",
    "Most supervised learning techniques fall into this exact framework, and they use a linear function class, such as:\n",
    "\n",
    "$$ \\mathcal{F} \\triangleq \\{\\mathcal{F}_\\theta (x) = \\sum_{l=1}^d \\theta_l x_l + \\theta_0 \\mid \\forall \\; \\theta_l \\in \\mathbb{R} \\}$$\n",
    "\n",
    "Linear function classes work well in many settings, but they struggle to model more complex patterns. This is where the kernel method (and later neural networks) come in.\n",
    "\n",
    "#### **Basis Functions**\n",
    "\n",
    "Basis functions, $\\phi(x)$ can be viewed as mapping $x$ to some variable. An example of a basis function is the polynomial basis function:\n",
    "\n",
    "$$ \\phi_l(x0) = x^l \\implies 1, x, x^2, \\dots $$\n",
    "\n",
    "#### **A Basic and Naive Approach to Building Nonlinear Approximation**\n",
    "\n",
    "A very basic and naive way to incorporate nonlinear functions into $\\mathcal{f}$ is to replace the feature with a set of nonlinear basis functions. So\n",
    "\n",
    "$$ f(x, \\theta) = \\sum_{l=1}^d \\theta_l x_l = \\theta^\\intercal x $$\n",
    "\n",
    "becomes\n",
    "\n",
    "$$ f(x, \\theta) = \\sum_{l=1}^m \\theta_l \\phi_l(x) = \\theta^\\intercal \\phi(x) $$\n",
    "\n",
    "Where $\\phi(x) = [\\phi_1(x), \\dots, \\phi_m(x)]^\\intercal$ is a set of nonlinear basis functions believed to capture important nonlinear patterns regarding the input, and $\\theta = [\\theta_1, \\dots, \\theta_m]^\\intercal$ is the coefficient vector. For a fixed $phi(x)$, the coefficient $\\theta$ is estimated the same way as linear regression, so this has a simple closed form solution.\n",
    "\n",
    "The problem with this approach is that you must manually decide what type of basis function to use. This can be very problem dependent, and hand crafting different functions each time can be problematic.\n",
    "\n",
    "This is a very simple implementation, but the **key idea of converting the input space using a nonlinear transform into another input space, them performing linear regression on it** is fundamental to nonlinear approximations. \n",
    "\n",
    "#### **Building Flexible and Adaptive Nonlinear Approximation**\n",
    "\n",
    "Our goal is to have an algorithm that can automatically construct a set of basis functions, which we can then do linear regression on. This provides a very flexible nonlinear approximation. And if we can construct a lot of basis functions, we can make the approximation even more flexible. This is called an **adaptive basis function**. Both the kernel method and neural networks are methods to find adaptive basis functions.\n",
    "\n",
    "#### **The Kernel Method in Practice**\n",
    "\n",
    "Let's say we have a set of data points, $\\mathcal{D}$, that is two-dimensional. The idea of kernel methods is that we can represent each of the data points using its similarity with all the other data points. In the example below, the data point \"star\" can be characterized/identified by its similarity with all the other points. Further, the more and more data we have, the more dimensions we can use to represent this data point, the more flexible of a representation we have.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.6.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Generating a Similarity Score**\n",
    "\n",
    "In order to do this, we need to define a **similarity function**. This function takes two points and calculates a similarity score betwen them, a real number:\n",
    "\n",
    "$$ K(x,x') : X \\times X \\mapsto \\mathbb{R} $$\n",
    "\n",
    "Often we use Gaussian similarity functions, for example the Gaussian radial basis function (RBF) kernel:\n",
    "\n",
    "$$K(x, x') = exp(-\\frac{1}{2h^2}||x-x'||^2_2) $$\n",
    "\n",
    "Where $h$ is a hyperparameter called **Bandwidth**, which controls how quickly similarity decays with distance, and $||x-x'||^2_2$ is the Euclidean distance between $x$ and $x'$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7fd67-696a-40a3-9e6d-00ca9e6ddd04",
   "metadata": {},
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce61fc-115c-4357-a766-7faec52d2284",
   "metadata": {},
   "source": [
    "#### **Kernel Representation Benefits**\n",
    "\n",
    "- Flexibility: Kernel functions can map data into spaces where complex relationships become linear.\n",
    "- Nonlinearity: Even if $x$ and $x′$ have nonlinear relationships in the input space, they may appear linearly separable in the kernel space.\n",
    "- Avoiding Explicit Basis Functions: The kernel trick allows computations to be performed directly with $k(x,x′)$ without explicitly defining or computing the high-dimensional $\\phi(x)$.\n",
    "\n",
    "#### **How to Choose x to Represent in Kernel Space**\n",
    "\n",
    "- In prediction tasks, you will represent the query point (the input for which you would like an output) as $x$ in $\\phi(x)$.\n",
    "- If you want to analyze the relationships amongst the dat points, you can represent each point $x_i \\in \\mathcal{D}$ in kernel space to explore its similarity to other points in $\\mathcal{D}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
