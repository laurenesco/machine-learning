{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be158dc-a876-43cb-9c39-279dd11cea45",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41c711-1504-4cd0-93a3-aa8a6963a859",
   "metadata": {},
   "source": [
    "## ***Vocabulary***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ceb54-7137-431e-8ae1-1053d0f2bcbe",
   "metadata": {},
   "source": [
    "- **empirical data**\n",
    "    - data gathered through empirical means (e.g., observations, measurements, experiments, simulations, etc.). this type of data allows ai models to learn from real-world examples and test against practical scenarios\n",
    "- **realistic data**\n",
    "    - data which mimics the complexity, variability, and noise found in the real-world. this type of data should capture the imperfections fo real world processes \n",
    "- **multimodality**\n",
    "    - \"multimodal\" refers to receiving, processing, or outputting media of multiple forms (modalities) (e.g., audio, video)\n",
    "- **stochastic**\n",
    "    - systems or processes that are random or involve some degree of randomness. in a stochasic system, outcomes are not deteministic. outcomes can vary even, even under the same conditions. you cannot predict the exact outcome, but can describe their likelihood using probabilities\n",
    "- **multivariate**\n",
    "    - refers to something that uses multiple variables or features\n",
    "- **argmax**\n",
    "    - \"argument of the maximum\", the input value that produces the maximum output of a given function\n",
    "- **second-derivate test**\n",
    "    - Second derivative > 0: Local minimum.\n",
    "    - Second derivative < 0: Local maximum.\n",
    "    - Second derivative = 0: Test is inconclusive, and further analysis is needed.\n",
    "- **parametric distribution**\n",
    "    - distribution of the same mathematical form that has a finite number of certain parameters, that once known, describe the distribution completely. for example, the gaussian distribution uses $\\sigma^2$ for variance and $\\mu$ for the mean. exponential distribution uses $\\gamma$ for the decay rate. different parameters outline different behaviours for the distributions.\n",
    "- **closed-form solution**\n",
    "    - an explicit mathematical expression which can be evaluated in a finite number of standard operations. it does not require iterative procedures or methods.\n",
    "- **sum of squared differences**\n",
    "- **asymptotically**\n",
    "- **regularity**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc47029-8dd1-4934-8f85-9487837b1e2c",
   "metadata": {},
   "source": [
    "# Lecture Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eb618-a347-4dd5-bb64-a4efac8cacf4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ***2.1.0 Introduction***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d5883-6aa1-4df8-bc9a-45b3f4f0d46d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Intuition/Background/Example 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9eea8c-ab5e-4392-9fb0-ed86d3ce1a76",
   "metadata": {},
   "source": [
    "#### **Introduction**\n",
    "\n",
    "Maximum likelihood estimation is a way to estimate parameters for given probabalistic distributions from observation.\n",
    "\n",
    "#### **Problem Statement**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "In this example, we can very intuitively estimate $\\theta = \\frac{4}{5}$. However, is there a theoretical and mathematical way to estimate this parameter that we can apply to more complex problems? **Maximum likelihood estimation does exactly that**.\n",
    "\n",
    "#### **Basis for MLE**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Simplifying the problem, let's compare the probability that $\\theta$ equals 0.1 or 0.9. These values can actually be calculated using the probabilistic rule since we have some independent draws from the distribution. As we can see after calculating both, the likelihood that $theta = .9$ is much higher than the likelihood that $\\theta = .1$. This is the basis for estimating parameters using maximum likelihood estimation.\n",
    "\n",
    "In practice, we can do this same process for every value between 0 and 1. By doing this, we can create a function, a likelihood function, that evaluates how likely each parameter is. Then, we can maximize that likelihood function to find the optimal esimtation.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Applying MLE**\n",
    "\n",
    "In the case of the example problem, the likelihood function and maximum likelihood estimation would be as follows:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "So, we end up with the optimization problem:\n",
    "\n",
    "$$ \\hat{\\theta} = \\underset{\\theta}{argmax}\\; \\theta^4\\;(1-\\theta) $$\n",
    "\n",
    "#### **Log-Likelihood**\n",
    "\n",
    "And it turns out there is a nice trick to solve this problem, we can maximize the log of the function instead (because the log is monotonically increasing). Thus, we are solving the log-likelihood function:\n",
    "\n",
    "$$ \\hat{\\theta}  = \\underset{\\theta}{argmax}\\; log(\\theta^4\\;(1-\\theta)) $$\n",
    "$$ = 4\\;log\\;\\theta+log\\;(1-\\theta) $$\n",
    "$$ \\ell(\\theta) \\triangleq log\\;L(\\theta) $$\n",
    "\n",
    "Then, we can calculate the gradient of this function (by taking the derivative), and find the point where the gradient 0. This will yield the maximum of the fuction, as long as the second derivate test confirms it's a maximum. The gradient for this problem is:\n",
    "\n",
    "$$\\nabla \\ell(\\theta) = \\frac{4}{\\theta}+\\frac{-1}{1-\\theta} = 0 \\implies \\hat{\\theta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20199f8a-416c-4b2a-8f36-2cb7eb255cab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Family of Problems MLE can Solve**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "So we can define the likelhood function as:\n",
    "\n",
    "$$ L(\\theta) = P(x_1, \\dots, x_n | \\theta) $$\n",
    "\n",
    "Which, since the observations are drawn independently, is a product of probabilities:\n",
    "\n",
    "$$ \\prod_{i=1}^n P(x_i|\\theta) $$\n",
    "\n",
    "And as we said, its easier to work with logs when working with many products, so we will often prefer to use the log-likelihood function:\n",
    "\n",
    "$$ \\ell = log\\;L(\\theta) = log(\\prod_{i=1}^n P(x_i|\\theta)) $$\n",
    "\n",
    "**Thus, we can define the log-likelihood function as:**\n",
    "$$ = \\sum_{i=1}^n log P(x_i|\\theta) $$\n",
    "\n",
    "**We can then describe the maximum likelihood estimation as:** \n",
    "\n",
    "$$ \\hat{\\theta} = \\underset{\\theta}{argmax}\\;\\ell(\\theta) = \\underset{\\theta}{argmax}\\{\\sum_{i=1}^n log P(x_i|\\theta)\\} $$\n",
    "\n",
    "#### **Formally, the Steps of MLE**\n",
    "1. Define the likelihood function\n",
    "2. Calculate the log-likelihood function\n",
    "3. Maximize the log-likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7571c-c9db-45bf-bbb7-17fcdaaf8fe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Example 2: Biased Coin Revisted; Bernoulli Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7693bb-19a9-448d-8fab-63f07422baef",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "This is another binary problem. Notice that the sigmoid function $\\frac{\\exp(w)}{1+exp(w)}$ is being used. This transformation maps any real-valued number $w \\in (-\\infty, \\infty)$ to a value $\\theta \\in (0,1)$.\n",
    "\n",
    "**Step 1: Define Likelihood Function**\n",
    "\n",
    "$$L(w) = P(x_1, \\dots, x_n | w)$$\n",
    "$$ = \\prod_{i=1}^n P(x_i|w) $$\n",
    "\n",
    "**Step 2: Calculate Log-Likelihood Function**\n",
    "\n",
    "Now a problem that we have is that the probability is on a case by case basis. If $x_i = 0$, then we use one probability, if $x_i = 1$, we use the other. Fortunately, we can actually write these probabilites in a unified form:\n",
    "\n",
    "$$ Pr(x) = \\frac{exp(xw)}{1+exp(w)} $$\n",
    "\n",
    "Proof:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.7.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Plugging in that formula to get the expression for each $x$:\n",
    "\n",
    "$$ log\\;Pr(x|w) = log(\\frac{exp(xw)}{1+exp(w)}) $$\n",
    "$$ = xw-log(1+exp(w)) $$\n",
    "\n",
    "Recall the formula for likelihood of $w$, and plug in the log-likelihood formula derived:\n",
    "\n",
    "\n",
    "$$ \\ell(w) = log(L(w)) = log(\\prod_{i=1}^n P(x_i|w))$$\n",
    "$$ = \\sum_{i=1}^n [x_iw-log(1+exp(w))] $$\n",
    "\n",
    "Simplifying:\n",
    "\n",
    "$$ = (\\sum_{i=1}^n x_i)w-n\\;log(1+exp(w)) $$\n",
    "$$ = n(\\bar{x}w - log(1+exp(w))) $$\n",
    "\n",
    "**Step 3: Optimize Log-Likelihood Function**\n",
    "\n",
    "$$ \\hat{w} = \\underset{w}{argmax}\\;\\ell(w) = \\underset{w}{argmax}\\{n(\\bar{x}w - log(1+exp(w)))\\} $$\n",
    "\n",
    "We will start by taking the gradient:\n",
    "\n",
    "$$ \\nabla \\ell(w) = \\frac{d}{dx}\\; n(\\bar{x}w - log(1+exp(w))) $$ \n",
    "$$ = n(\\bar{x}-\\frac{exp(w)}{1+exp(w)}) $$\n",
    "\n",
    "And we want to find where this gradient equals 0.\n",
    "\n",
    "Here are some other equivalent ways to write that final optimization problem:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.8.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a2c9d-9554-4c7b-a4b1-2f32161160f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Example 3: Gaussian Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73b1ae-814d-40b2-9d92-632a90dcadde",
   "metadata": {},
   "source": [
    "#### **Setup**\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.9.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Here we have $x$ drawn from a Gaussian distribution, which is indexed on two parameters, $\\mu$, and $\\sigma$.\n",
    "\n",
    "Since we already have the formula for $P(x|\\theta)$, we will jump straight into step 2. The log-likelihood function can be defined as:\n",
    "\n",
    "$$ \\ell(\\theta) = \\sum_{i=1}^n (log\\frac{1}{(2\\pi)^{1/2}\\sigma})-\\frac{1}{2\\sigma^2}(x_i-\\mu)^2 $$\n",
    "\n",
    "And in this case we have two parameters, so theta is sigma and mu here.\n",
    "\n",
    "Simplifying:\n",
    "\n",
    "$$ \\ell(\\theta) = \\frac{-n}{2}log(2\\pi)-n\\;log\\;\\sigma-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2 $$\n",
    "\n",
    "This is what we want to maximize.\n",
    "\n",
    "#### **Optimizing mu**\n",
    "\n",
    "If say we want to maximize $\\mu$, we only need to look at the terms that depend on $\\mu$, as any other term is a constant with respect to $\\mu$. Thus, the term we will look at is:\n",
    "\n",
    "$$ -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n(x_i-\\mu)^2 $$\n",
    "\n",
    "And since $\\frac{1}{2\\sigma^2}$ is a constant with respect to optimizing $\\mu$ (for a fixed $\\sigma$ while maximizing $\\mu$), the optimization problem turns into the following minimization problem:\n",
    "\n",
    "$$ \\hat{\\mu} = \\underset{\\mu}{argmin}\\{\\sum_{i=1}^n(x_i-\\mu)^2\\} $$\n",
    "\n",
    "This is because $x_i-\\mu$ corresponds to how far a data point is from the mean, and we want to minimize that value to choose the best $\\mu$. Also because it is preceeded by a negative sign, so the smaller it is, the more we maximize the overall function.\n",
    "\n",
    "Calculating the gradient, we get:\n",
    "\n",
    "$$ \\sum_{i=1}^n2(\\mu-x_i)=0 \\implies \\hat{\\mu} = \\frac{1}{n}\\sum_{i1}^nx_i $$\n",
    "\n",
    "As shown here:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.10.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Optimizing sigma**\n",
    "\n",
    "Only the second and third term rely on $\\sigma$, so our optimization problem turns into:\n",
    "\n",
    "$$ \\hat{\\sigma} = \\underset{\\sigma}{argmax}\\{-n\\;log\\;\\sigma-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\hat{\\mu}^2\\} $$\n",
    "\n",
    "Which we will define as $f(\\sigma)$. The gradient can be calculated as:\n",
    "\n",
    "$$ \\nabla f(\\sigma) = -\\frac{n}{\\sigma}-\\frac{(-2)1}{2\\sigma^3}  \\sum_{i=1}^n(x_i-\\hat{\\mu})^2 $$\n",
    "\n",
    "Solving for this gradient set to 0:\n",
    "\n",
    "$$ \\implies \\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\hat{\\mu})^2 $$\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "Both optimizing $\\mu$ and optimizing $\\sigma$ turned out very nice, as $\\mu$ ended up being the mean value of the $x_i$'s, and $\\sigma$ ended up being the emprical variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27d392-d186-4546-bb04-210e9c53e650",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Example 4: Uniform Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71929c-e025-49b9-b6d1-7fffeb57c5d8",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.11.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "This problem involves the uniform distribution, for which the function is as shown below. It is a step function. Anything in the green shaded area will evaluate to $\\frac{1}{\\theta}$, any point anywhere else will evaluate to 0. \n",
    "\n",
    "It is shown that both orange shaded areas can be used to estimate $\\theta$ given the observations shown in red, but we we want to keep $\\theta$ as small as possible. We can use MLE to get the optimal $\\theta$.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.12.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Step 1: Defining**\n",
    "\n",
    "We will start by rewriting the probability function in terms of $x$:\n",
    "\n",
    "$$ P(x|\\theta) = \\frac{1}{\\theta}1(x\\in[0,\\theta]) $$\n",
    "\n",
    "#### **Step 2: Calculating**\n",
    "\n",
    "Deriving the likelihood function:\n",
    "\n",
    "$$ L(\\theta) = \\prod_{i=1}^n P(x_i|\\theta) $$\n",
    "$$ = \\prod_{i=1}^n(\\frac{1}{\\theta})1(x_i\\in[0,\\theta]) $$\n",
    "$$ = (\\frac{1}{\\theta})^n \\prod_{i=1}^n 1(x_i\\in[0,\\theta]) $$ \n",
    "\n",
    "Which, due to the conditionality (we are looking at the product of a bunch of indicator functions), we can further simplify this expression to:\n",
    "\n",
    "$$ L(\\theta) = \n",
    "\\begin{cases}  \n",
    "(\\frac{1}{\\theta})^n & \\text{if } x_i \\in [0, \\theta] \\;\\; \\forall i \\\\ \n",
    "0 & \\text{otherwise} \n",
    "\\end{cases} $$\n",
    "\n",
    "#### **Step 3: Maximizing**\n",
    "\n",
    "That piecewise is what we want to maximize. And since this is a step function, we want to ensure that $\\theta$ includes all observations. Thus, $\\theta$ must enclose all the observations, and the largest $x_i$ will be the best choice for $\\theta$.\n",
    "\n",
    "\n",
    "Below is the likelihood function graphed, which proves that the largest $x_i$ is the best choice for $\\theta$.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.13.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$ \\hat{\\theta} = max\\{x_1, \\dots, x_n\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3093d-a124-4a84-8f18-5b8c4e132330",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Example 4: Regression; Gaussian Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d7267-8f45-4e45-a87c-458a05de5872",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.14.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "It turns out that MLE can be used for more complicated problems such as regression. Regression is when we have a pairs of variables and we want to understand the relationship between the feature (typically $x_i$) and the variable (typically $y_i$). Basically, we want to fit a curve to predict $y$ given $x$.\n",
    "\n",
    "#### **Step 1: Defining**\n",
    "\n",
    "**Breaking down the given probability:**\n",
    "Its a pretty reasonable to assume that $y$ is generated from some distribution. Another typical assumption we can make is that we can assume, conditioned on each $x_i$, $y$ is following some gaussian distribution whose mean is some function class, and we also have some variance $\\sigma^2$.\n",
    "\n",
    "This graph outlines these principles visually, where $f(x,\\theta)$ is the mean conditioned on $x$, and $\\sigma^2$ is the variance, which determines where the point will fall.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.15.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Instead of maximizing a single likelihood, we maximize the conditional likelihood.\n",
    "\n",
    "$$ \\ell(\\theta, \\sigma) = \\sum_{i=1}^n log\\;P(y_i|x_i, \\theta) $$\n",
    "\n",
    "#### **Step 2: Calculating**\n",
    "\n",
    "Using the same formula derived in Example 3, but replacing $\\mu$ with the mean function:\n",
    "\n",
    "$$ \\ell(\\theta, \\sigma) = \\sum_{i=1}^n [\\frac{-n}{2}log(2\\pi)-n\\;log\\;\\sigma-\\sum_{i=1}^n\\frac{1}{2\\sigma^2}(y_i-f(x_i\\theta))^2 $$\n",
    "\n",
    "#### **Step 3: Maximizing**\n",
    "\n",
    "$$ \\underset{\\theta}{max}\\;\\ell(\\theta,\\sigma) \\implies \\underset{\\theta}{min}\\sum_{i=1}^n(y_i-f(x_i\\theta))^2 $$\n",
    "\n",
    "And for sigma, after finding $\\hat{\\theta}$:\n",
    "\n",
    "$$ \\hat{\\sigma} = \\frac{1}{n}\\sum_{i=1}^n (y_i=f(x_i\\hat{\\theta}))^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684c0c1-44a9-47e8-ad55-91298333a4d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Example 5: Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb3c9b-095c-4a36-aa7d-ab51ee448968",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.16.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "While regression is when we have a pairs of variables and $y$ is a real number, in logistic regression $y$ is a binary variable, or label, conditioned on $x$. That is, logistic regression is a classification problem.\n",
    "\n",
    "This problem is essentially an extension of the Bernoulli example we saw earlier, replacing $w$ with this function $f(x;\\;\\theta)$.\n",
    "\n",
    "#### **Step 1: Defining**\n",
    "\n",
    "Given the above probability, we can derive that:\n",
    "\n",
    "$$ P(y=1|x,\\theta) = \\frac{exp(f(x,\\theta))}{1+exp(f(x,\\theta))} $$\n",
    "\n",
    "$$ P(y=0|x,\\theta) = \\frac{1}{1+exp(f(x,\\theta))} $$\n",
    "\n",
    "#### **Step 2: Calculating**\n",
    "\n",
    "In this case we don't need the log-likelihood function. That's because above we transformed the probabilites into a sigmoid function.\n",
    "\n",
    "#### **Step 3: Maximizing**\n",
    "\n",
    "$$ max \\sum_{i=1}^n log\\;P(y_i|x_i,\\theta) $$\n",
    "$$ = \\sum_{i=1}^n(y_i\\;f(x_i,\\theta)-log(1+exp(f(x_i,\\theta)))) $$\n",
    "$$ \\triangleq \\ell(\\theta) $$\n",
    "\n",
    "In this case, its difficult or impossible to derive a closed form solution for the optimal theta using numerical methods. One of the most widely used algorithms for solving this problem is **gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e98bf-fd88-4e2e-adc1-735dd83b8874",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da267557-d96f-4f0c-b0eb-f513929e8e0a",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.17.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Emphasis on MLE estimator being a random variable estimated using bias, variance, and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6037a-5a71-4419-8ec7-4e35c68d6296",
   "metadata": {},
   "source": [
    "## ***2.1.1 Theoretical Properties***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50050cb2-65de-4374-b1bb-6eba13c90e5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b44f3-327e-4400-822b-cd5400453794",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.18.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "The first thing we want to highlight is that the MLE estimator is a **random variable**. That is because the MLE estimator is a function of $x$, which is drawn iid from a distribution. That is, $x$ is a random variable. Since $\\hat{\\theta}$ is a function of $x$, its also a random variable. Because it is a random variable, we must understand the statistical properties of $\\hat{\\theta}$.\n",
    "\n",
    "This section will define the properties bias, variance, and mean square error properties of the MLE estimator and the relation between them. It will also define unbiased and consistent estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7d489-156b-446e-bc3f-34f17ecec513",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cb4ff-5190-4f42-b264-53a7cf925c64",
   "metadata": {},
   "source": [
    "#### **Definition:** \n",
    "The bias is simply the difference of the expectation of the MLE with respect to the true parameter.\n",
    "\n",
    "$$ Bias(\\hat{\\theta}) = \\mathbf{E}_{\\theta^*}[\\hat{\\theta}(x_1, \\dots, x_n)] - \\theta^* $$\n",
    "\n",
    "Where $\\theta^*$ is the true parameter. This can be more explicity with the definition of the expected values as:\n",
    "\n",
    "$$ \\int \\hat{\\theta}(x_1, \\dots, x_n) \\prod_{i=1}^nP(x_i|\\theta^*)\\;dx - \\theta^* $$\n",
    "\n",
    "Which is a fairly complicated formula adn wouldn't be able to have a closed-form solution for complicated cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f463b2d-0248-4610-9e96-5c82feea3fd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b99ee-358e-407b-9287-a518b28c0de3",
   "metadata": {},
   "source": [
    "#### **Definition:** \n",
    "The variance represents the fluctuation around the mean. \n",
    "\n",
    "$$ Var(\\hat{\\theta}) = \\mathbf{E}_{\\theta^*}[(\\hat{\\theta}(x_1, \\dots, x_n)-\\mathbf{E}_{\\theta^*}(\\hat{\\theta}(x_1, \\dots, x_n)))^2] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a699a83-2997-41ed-bc33-5cea43dbb948",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Mean Squared Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5142c09-e5e9-493d-8869-c973ab0ee9f3",
   "metadata": {},
   "source": [
    "#### **Definition:** \n",
    "The MSE measures the quality of the estimator produced by MLE.\n",
    "\n",
    "$$ MSE(\\hat{\\theta}) = \\mathbf{E}_{\\theta^*}[(\\hat{\\theta}(x_1, \\dots, x_n) - \\theta^*)^2] $$\n",
    "\n",
    "Note that the MSE subtracts the true parameter from the epected value of the estimated parameter. In this way **MSE is a very direct estimation of the quality of the MLE estimator**. We want to design the MLE to minimize this value as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7395cd-26c3-4dce-a245-1ed538e370c5",
   "metadata": {},
   "source": [
    "### **Relating Bias, Variance, and MSE; the Bias-Variance Decomposition**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22657043-a07c-4df4-ad56-2173b589b364",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Bias-Variance Decomposition Equation**\n",
    "\n",
    "$$ MSE(\\hat{\\theta}) = (Bias(\\hat{\\theta}))^2 + Var(\\hat{\\theta}) $$\n",
    "\n",
    "#### **Proof**\n",
    "\n",
    "Note: We are dropping the dependency of $\\hat{\\theta}$ on $x_1$ through $x_n$ in order to simplify this notation for the proof. Starting with the definition of MSE:\n",
    "\n",
    "$$ MSE(\\hat{\\theta}) = \\mathbf{E}[(\\hat{\\theta}-\\theta^*)^2] $$\n",
    "\n",
    "Expanding by adding and subtracting the same term inside the expression (completing the square) making a quadratic formula:\n",
    "\n",
    "$$ = \\mathbf{E}[(\\hat{\\theta}-\\mathbf{E}(\\hat{\\theta}) + \\mathbf{E}(\\hat{\\theta})-\\theta^*)^2] $$\n",
    "\n",
    "Expanding out the square:\n",
    "\n",
    "$$ = \\mathbf{E}[(\\hat{\\theta}-\\mathbf{E}(\\hat{\\theta}))^2 + (\\mathbf{E}(\\hat{\\theta})-\\theta^*)^2 + 2(\\hat{\\theta}-\\mathbf{E}(\\hat{\\theta}))(\\mathbf{E}(\\hat{\\theta})-\\theta^*) ] $$\n",
    "\n",
    "Showing that this expression is equivalent to the initial equation:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.19.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Proving that the final term equals 0:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.20.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Importance**\n",
    "\n",
    "This equation is critical, because oftentimes there will be a trade-off between bias and variance when performing MLE. By trading off these terms, we can find a sweet point where the sum of them is minimized, so we can optimize the overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607c5d8-4ffe-4412-9349-e94aaf19a77b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Unbiased and Consistent Estimators**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50b0eac5-5326-40fe-b4f7-30e09175a737",
   "metadata": {},
   "source": [
    "#### **Unbiased Estimator Definition**\n",
    "If an estimator has a bias of 0 ($Bias(\\hat{\\theta}) = 0$) then we call $\\hat{\\theta}$ an unbiased estimator. We call this an unbiased estimator.\n",
    "\n",
    "#### **Consistent Estimator Definition**\n",
    "If the $MSE(\\hat{\\theta})$ moves toward 0 as the amount of data, $n$, moves to $\\infty$, then $\\hat{\\theta}$ is consistent.\n",
    "\n",
    "#### **Relation to One Another**\n",
    "\n",
    "It is important to note that these are two very different properties, and the presence of one does not indicate the presence of the other. Specifically, an unbiased estimator may still have some varaince, meaning the MSE will not converge to 0 with infinite data. Conversely, a consistent estimator may still have some bias for a finite amount of data.\n",
    "\n",
    "#### **Asymptotic Unbiasedness**\n",
    "This is the case when the bias goes to 0 as $n$ goes to $\\infty$. Having a consistent estimator **does** imply asymptotic unbiasedness, but it does not imply direct unbiasedness.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.19.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "We can see that this is a Gaussian distribution problem. (See Example 3 from 2.1.0)\n",
    "\n",
    "Looking at $\\hat{\\mu}$ first, cheking for unbiasedness:\n",
    "\n",
    "$$ Bias(\\hat{\\mu}) = \\mathbf{E}[\\hat{\\mu}]-\\mu $$ \n",
    "$$ = \\mathbf{E}[\\frac{1}{n}\\sum_{i=1}^nx_i]-\\mu $$ \n",
    "$$ = \\frac{1}{n}\\sum_{i=1}^n\\mathbf{E}[x_i]-\\mu $$ \n",
    "$$ = \\frac{1}{n} \\sum_{i=1}^n\\mu - \\mu $$\n",
    "$$ = 0 $$\n",
    "\n",
    "Now checking variance:\n",
    "\n",
    "$$ Var(\\hat{\\mu}) = \\mathbf{E}[(\\hat{\\mu}-\\mu)^2] $$\n",
    "$$ = \\mathbf{E}[(\\frac{1}{n}\\sum_{i=1}^nx_i-\\mu)^2] $$\n",
    "$$ = \\mathbf{E}[\\frac{1}{n^2}(\\sum_{i=1}^n(x_i-\\mu)^2+\\sum_{i\\ne j}^n(x_i-\\mu)(x_j-\\mu)] $$\n",
    "$$ = \\frac{1}{n^2}\\sum_{i=1}^n\\mathbf{E}((x_i-\\mu)^2) + \\sum_{i\\ne j}^n\\mathbf{E}[( x_i-\\mu)(x_j-\\mu)]$$\n",
    "$$ = \\frac{1}{n}\\sigma^2 $$\n",
    "\n",
    "Now that we have both of those, we can check if the estimator is consistent:\n",
    "\n",
    "$$ MSE(\\hat{\\mu}) = (Bias(\\hat{\\mu}))^2 + Var(\\hat{\\mu}) $$\n",
    "$$ = \\frac{\\sigma^2}{n} $$\n",
    "\n",
    "Thus, as $n \\to \\infty$, $MSE(\\hat{\\mu}) \\to 0 \\implies$ consistent.\n",
    "\n",
    "We can say that this estimator, $\\hat{\\mu}$, is unbiased and consistent. It can be shown (but we will not prove it here) that $\\hat{\\sigma^2}$ is biased, but is asymptotically ubiased and consistent:\n",
    "\n",
    "$$ Bias(\\hat{\\sigma^2}) \\to 0 \\;\\; n \\to \\infty $$\n",
    "$$ Var(\\hat{\\sigma^2}) \\to 0 \\;\\; n \\to \\infty $$\n",
    "$$ MSE(\\hat{\\sigma^2}) \\to 0 \\;\\; n \\to \\infty $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ceb74-fd2c-43fd-8006-37eaa3024d1e",
   "metadata": {},
   "source": [
    "### **Kullback-Leibler Divergence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1e100-1439-46b7-a41d-9b1321183db0",
   "metadata": {},
   "source": [
    "#### **Why MLE?**\n",
    "\n",
    "It turns out that in most cases an MLE estimator can be shown to be consistent (save for weird cases where regularity doesn't hold). \n",
    "\n",
    "***Question: Why is MLE always consistent?*** \\\n",
    "It turns out that MLE can be viewed as minimizing the notion of difference measured by the KL Divergence. The KL Divergence measures the difference between two distributions. So MLE is minimizng the difference between the data distribution and the model distribution.\n",
    "\n",
    "#### **Understanding KL Divergence**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.22.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Above is the definition of the KL divergence. We can see that the formula explicitly written for a discrete $x$ is a summation, and for a continuous $x$ is an integration.\n",
    "\n",
    "Another thing to note is that this equation is not symmetric:\n",
    "\n",
    "$$ KL(q||p) \\ne KL(p||q) $$\n",
    "\n",
    "However, the KL divergence is **always** non-negative, and if KL divergence = 0, then $p = q$.\n",
    "\n",
    "#### **Jensen's Inequality**\n",
    "\n",
    "If $f(x)$ is convex, then we can show that $\\mathbf{E}_q[f(x)] \\ge  f(\\mathbf{E}(x))$, the expected value of f(x) is always greater than the f(expected value of x).\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.23.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Proving Property 1 of RL Divergence**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.24.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Proving Property 2 of RL Divergence**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.25.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Connection**\n",
    "\n",
    "As it turns out, minimizing the KL Divergence IS maximizing log-likelihood. Thus, it is MLE.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.1.26.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7fd67-696a-40a3-9e6d-00ca9e6ddd04",
   "metadata": {},
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce61fc-115c-4357-a766-7faec52d2284",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
