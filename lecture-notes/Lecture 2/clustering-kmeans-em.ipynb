{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be158dc-a876-43cb-9c39-279dd11cea45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Clustering, K-means, Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41c711-1504-4cd0-93a3-aa8a6963a859",
   "metadata": {},
   "source": [
    "## ***Vocabulary***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ceb54-7137-431e-8ae1-1053d0f2bcbe",
   "metadata": {},
   "source": [
    "na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc47029-8dd1-4934-8f85-9487837b1e2c",
   "metadata": {},
   "source": [
    "# Lecture Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eb618-a347-4dd5-bb64-a4efac8cacf4",
   "metadata": {},
   "source": [
    "## ***K-Means***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f62733-f1e1-4728-9c65-bfc8e4fe9956",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e260c6-7729-43a1-b64c-13e28fcafbb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Clustering is an important **unsupervised** learning task. The **goal** is to partition the dataset into similar groups. **Use cases** include categorizing news stories for easier sorting and locating by readers, or discovering distinct groups in a customer base for marketing campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619d77b-6780-4d3f-96e0-4f5725300082",
   "metadata": {},
   "source": [
    "### **K-means Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb9171-bc72-411f-83ab-5d25a15d929e",
   "metadata": {},
   "source": [
    "#### **Context for K-means**\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "K-means takes $n$ objects, where each $x_i$ could be a vector itself where each coordinate represents different information. For example, $x_i^1$ might represent the dollars this particular customer spends on electronics, whereas $x_i^2$ might represent dollars spent by this customer in another category. \n",
    "\n",
    "We also have $K$, which is the number of clusters we want to partition the data points into. $K$ must be given in K-means algorithm, so if you don't know the best $K$, you will have to experiment and choose the best one. There are also data driving approaches that allows us to estimate the best $K$ automatically, however these appraoches will not be covered in class. \n",
    "\n",
    "With the data and $K$ given, we want to decide how to partition the data. We also want to determine a centroid for each of the clusters. The **centroid** is the representative data point for each cluster. Empirically, the centroid will be the average or geometric center within the cluster.\n",
    "\n",
    "#### **Goal of K-means**\n",
    "**So, the K-means algorithm must jointly determine the assignment and the centroids that provides an optimal partition of the data.**\n",
    "\n",
    "#### **High Level Algorithm**\n",
    "\n",
    "The K-means algorithms works by using the idea that we don't know the centroid and the assignments, so we start from **random initialization**. After randomly initializing either the centroids or the assignments, we iteratively update them so that they can be improved sequentially. These steps will be repeated until the the solution converges.\n",
    "\n",
    "#### **Illustrative Example**\n",
    "\n",
    "Here we have a simple dataset of 3 points in red. We wan to classify these three data points using clustering into 2 groups, $K = 2$. The process is as follows:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"40%\" src=\"images/2.3.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "1. Start with random initialization of the centroids. This location will of course not be a reasonable estimation of the centroids.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"40%\" src=\"images/2.3.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "2. Perform the assignment step of the data points to centroids, then update the centroids. Perform this iteratively until convergence.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"40%\" src=\"images/2.3.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Formal Algorithm Recap**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Input:** Data points $x_1, \\dots, x_n$, number of clusters $K$.\n",
    "\n",
    "**Algorithm:** \n",
    "- Randomly place $K$ points as the centroids\n",
    "- Iterate until convergence:\n",
    "\n",
    "1. Assign each data point to the closest centroid, where $z_i \\in \\{1,\\dots,K\\}$ is the centroid that data point is assigned to, and $\\mu_k$ represents the center of $k$'s cluster.\n",
    "\n",
    "$$z_i = \\underset{k=1,\\dots,K}{arg min}\\; ||x_i-\\mu_k||$$\n",
    "\n",
    "   2. Recalculate the position of the $K$ centroids, where $S_k$ is the set of data points belonging to centroid $k$, and $\\mu_k$ is the center of the centroid. Here we are assigning $mu_k$ to thea average mean of the datapoints assigned to centroid $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f3630-f585-4d8e-b90a-4b0db06cb9de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **K-means as Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fbd49-9022-4146-9d7c-2fa9a1f00738",
   "metadata": {},
   "source": [
    "#### **Defining K-means as an Optimization Problem**\n",
    "\n",
    "K-means is really just an optimization algorithm (something like coordinate descent), a very nice one, that guarantees convergence. \n",
    "\n",
    "Given ${x_i}^n_{i=1}$, we want ${\\mu_k}^K_{k=1}$, ${z_i}^n_{i=1}$. We will refer to the set of centers of the centroids as $\\mu$, and he set of data points belonging to each centroid as $z$.\n",
    "\n",
    "We need to define an objective function (loss function) that defines how well the data is partitioned:\n",
    "\n",
    "$$ L(\\mu,z) = \\sum_{i=1}^n ||x_i-\\mu_{z_i}||^2$$\n",
    "\n",
    "Remember that $z_i$ is the index of the centroid assigned to $x_i$.\n",
    "\n",
    "So, viewing K-means as an optimization problem, our goal is to solve:\n",
    "\n",
    "$$ \\underset{\\mu,z}{min} \\; L(\\mu,z) $$\n",
    "\n",
    "Which is actually a mized optimization problem, since $\\mu$ is continuous ($\\mu \\in \\mathbf{R}^{d\\times K}$) and z is discrete ($z \\in\\{1, \\dots, K\\}^n$), so it's a tricky optimization problem. It is not a convex optimization problem, and in fact there will be many local minima. However, the K-means algorithm we just introduce actually tries to exactly minimize the optimization problem by using the idea of coordinate descent, which allows us to update $\\mu$ and $z$ alternatively.\n",
    "\n",
    "#### **Coordinate Descent**\n",
    "The steps of coordinate descent are:\n",
    "- Initialize $\\mu$\n",
    "- Repeat:\n",
    "    - Update $z$, with fixed $\\mu$\n",
    "    - Update $\\mu$, with fixed $z$\n",
    " \n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.7.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Solving mathematically:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.8.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184745a-c560-467b-bc71-70910b997ce5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Things to Pay Attention to for This Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a810ca-f90c-40af-abd9-b97e4becc15b",
   "metadata": {},
   "source": [
    "#### **Local vs. Global Minima**\n",
    "\n",
    "The loss function for this problem is not convex, meaning there will be a lot of local minumums. Since we are starting with random initialization, we may just end up finding a random local optimal solution when running K-means. (Finding the global minimum is a very difficult problem). This means that K-means can be **very sensitive to the initialization**. In practice, you can try several different initializations, and choose the best solution that minimizes the loss.\n",
    "\n",
    "#### **Coordinate Descent Minimization Guarantee**\n",
    "\n",
    "The coordinate descent algorithm is actually guaranteed to find the local optimal solution. This is due to the nature of alternatively solving for $\\mu$ and $z$. Since we are finding the minimum solution while the other coordinate is fixed, the proceude can only decrease the loss function. Thus, we can say that coordinate descent monotonically decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ed5cd-43a9-4384-be36-0a59ee244e86",
   "metadata": {},
   "source": [
    "## **Expectation Maximization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb82a9-1780-4c14-9406-a59c82ba1d90",
   "metadata": {},
   "source": [
    "### **Context**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afaabd2-7e31-40aa-9a21-efcea6d6867d",
   "metadata": {},
   "source": [
    "#### **EM vs. K-means**\n",
    "Expectation maximization is another clustering algorithm which **generalizes the K-means algorithm**. EM solves the problem in K-means where, for data points which are tied between multiple centroid distances during assignment, you must randomly choose which centroid to assign the point to. **EM allows us to make probabilistic assignments of the data points**.\n",
    "\n",
    "**In EM, we make probabilistic assignments by calculating the probability of $z_i = k$ for any particular value instead of making a deterministic assignment for each data point.**\n",
    "\n",
    "#### **Probabilistic Assignment of Data Points**\n",
    "\n",
    "The probability calulated for each $z_i$ is taken to be proportional to distance, an example being taking the assignment using some type of sigmoid function (here lambda is some constant that is decided in the complete EM algorithm):\n",
    "\n",
    "$$ Prob(z_i=k) = \\frac{exp(-||x_i-\\mu_k||^2/\\lambda)}{\\sum_{i=1}^K exp(-||x_I-]\\mu_k||^2/\\lambda)} $$\n",
    "\n",
    "#### **Probabilistic Update of Centroids**\n",
    "\n",
    "Since we are defining randomizd assignments and we only maintain our probability, we must modify the mean to be a **weighted** average. The calculation of $\\mu_k$ for K-means can be written as an indicator function:\n",
    "\n",
    "$$\\mu_k = \\frac{\\sum_{i=1}^n\\mathbb{I}(z_i=k)x_i}{\\sum_{i=1}^n\\mathbb{I}(z_i=k)} $$\n",
    "\n",
    "For EM, we replace the deterministic indicator function with a soft probabalistic indicator:\n",
    "\n",
    "$$\\mu_k = \\frac{\\sum_{i=1}^nProb(z_i=k)x_i}{\\sum_{i=1}^nProb(z_i=k)} $$\n",
    "\n",
    "#### **Example**\n",
    "\n",
    "First we will calculate the probabilities that the data points belong to each centroid:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.9.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "After we have these probabilites, we can update the centroids. We do a weighted average using the probaility that each data point belongs to $z_i$:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.10.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "This process will be iterated until it converges.\n",
    "\n",
    "#### **Result using EM vs. K-means**\n",
    "\n",
    "We can see that the outcome will be different if we use EM or K-means, since K-means is uses deterministic (sometimes random) assignments.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.11.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### **Visualization**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.12.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"images/2.3.13.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7fd67-696a-40a3-9e6d-00ca9e6ddd04",
   "metadata": {},
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce61fc-115c-4357-a766-7faec52d2284",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
