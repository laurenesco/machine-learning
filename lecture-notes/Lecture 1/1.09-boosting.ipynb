{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf875b0-e362-4b39-84f5-f45cbe740310",
   "metadata": {},
   "source": [
    "# 1.9 Boosting #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356759d6-df6c-474d-8fcd-75f21d42a4b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ***Vocabulary & Code*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc50a90-cdf1-4e7c-a30e-53664cb19ad0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e912c3-51c7-4c9a-9d2d-a68db7de3891",
   "metadata": {},
   "source": [
    "# Lecture Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4b201-5879-4b79-8003-399aea6e83fb",
   "metadata": {},
   "source": [
    "## ***1.9.0 Introduction*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390f8d2-621e-43be-adb9-47cf6798e736",
   "metadata": {},
   "source": [
    "##### Recall two key parameters from PAC learning:\n",
    "- $\\delta$: probability of failure\n",
    "- $\\epsilon$: accuracy parameter\n",
    "\n",
    "Requirement:\n",
    "For any choice of $\\epsilon$ & $\\delta$, $A$ should output, with probability $\\ge 1-\\delta$, an $\\epsilon$ accurate classifier.\n",
    "\n",
    "A is allowed to run in time $poly(\\frac{1}{\\epsilon}\\frac{1}{\\delta})$, and its allowed to take a number of samples $poly(\\frac{1}{\\epsilon}\\frac{1}{\\delta})$.\n",
    "\n",
    "---\n",
    "\n",
    "Question: What if we have an algorithm, $A$, that with probability 5% outputs an $\\epsilon$ accurate classifier. How can we use A to obtain a standard PAC learner?\n",
    "\n",
    "We want to increase that 5% probability of success to $(1-\\delta)$. \n",
    "\n",
    "The solution is to run A a large number of times, say $t$. Then $Pr[A \\;fails\\; to\\; output\\;an\\; \\epsilon \\;accurate \\;classifier] \\le (0.95)^t$, if $A$ is run $t$ times.\n",
    "\n",
    "We can make $(0.95)^t$ very small by choosing $t$ to be $≈ O(log\\frac{1}{\\delta})$, then we can \"test\" each classifier generated during these $t$ trials to see if any of them are good classifiers.\n",
    "\n",
    "**Summary:** \\\n",
    "We have an algorithm that only succeeds with probability 5%, if we run it $t$ times, the proabability that it fails to ouput a classifier in all those $t$ times is at most $(0.95)^t$. So we can take to to be $O(log\\frac{1}{\\delta})$ and then the probability that it fails to output an accurate hypothesis over these $t$ trails is going to be smaller than $\\delta$. So with reasonable probability, one of these classifiers will be at least $\\epsilon$ accurate.\n",
    "\n",
    "---\n",
    "\n",
    "Trickier Question: What if $\\epsilon$ is fixed, to say .49?\n",
    "\n",
    "Imagine $A$ with probability $\\ge 1- \\delta$ ouputs a classifier with $\\epsilon = .49$.\n",
    "\n",
    "Natural Question: How do we amplify/improve the accuracy parameter? \n",
    "\n",
    "The solutions are called boosting algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "Adaboost overview:\n",
    "\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.9.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.9.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dd947-ce2b-486e-9e96-7fd3119b390c",
   "metadata": {},
   "source": [
    "## ***1.9.1 Adaboost*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29fb5c-eb42-4003-831a-47006a865834",
   "metadata": {},
   "source": [
    "Simplified Adaboost:\n",
    "\n",
    "Assume we have a training set of size $m$.\\\n",
    "Initially, the first distribution, $D_0$, is the uniform distribution, which corresponds to $w_i = 1 \\;\\forall_i$.\\\n",
    "The distribution is obtained by dividing by $W$, the sum of the weights.\n",
    "\n",
    "$E$ = error rate\\\n",
    "$A$ = accuracy = $1-E$\\\n",
    "$\\beta$ = $\\frac{E}{A}$\n",
    "\n",
    "Concretely: $E = \\frac{1}{2}-\\gamma$, $\\beta = \\frac{\\frac{1}{2}-\\gamma}{\\frac{1}{2}+\\gamma}$\n",
    "\n",
    "How to update the weights: at iteration $t$, run $A$ to obtain $h_t$\\\n",
    "For each $x_i$ such that $h_i(x_i)$ is correct:\n",
    "$$w_i^{new} = \\beta w_i^{old}$$\n",
    "For each $x_i$ such that $h_i(x_i)$ is incorrect:\n",
    "$$w_i^{new} = w_i^{old}$$\n",
    "\n",
    "Repeat for $T$ steps and output $maj(h_1, ..., h_T)$.\n",
    "\n",
    "---\n",
    "\n",
    "Claim: After $T$ iterations, the error $h_{final} = maj(h_1, ..., h_T) \\le e^{-2T\\gamma^2} \\implies choose\\;T≈\\frac{1}{\\gamma^2}lg(\\frac{1}{\\epsilon})$ then the error of $h_{final} \\le \\epsilon$\n",
    "\n",
    "Proving it:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.9.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.9.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.9.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6b775-65e0-4c63-ae8b-f3aac6dfe3dd",
   "metadata": {},
   "source": [
    "## ***1.9.2 Adaboost Modification*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab91c0-f259-4f25-8f98-f0f174c1fdb8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c49541e-abba-49ed-a164-dfdceee401c3",
   "metadata": {},
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d292d8-cf5e-4852-a842-5e6f4c95da84",
   "metadata": {},
   "source": [
    "**[Understanding Machine Learning: From Theory to Algorithms, Chapter 10](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
