{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3514d59-d7c3-4f7d-bd88-c37fefed19c3",
   "metadata": {},
   "source": [
    "# **1.1 Mistake-bounded Model of Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345bed0-7554-4895-8a51-f770ef980785",
   "metadata": {},
   "source": [
    "## ***Vocabulary*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da8ca7-f23c-4d2e-9d03-7a8a72656665",
   "metadata": {},
   "source": [
    "**Online Algorithm**: algorithms that process data sequentially, without knowing the entire input in advance.\n",
    "\n",
    "**Potential Function**: a mathematical tool used to analyze the behavior of algorithms, particularly in optimization or online learning. It maps the state of the algorithm to a real number to help us analyze the algorithms performance or certain properties about it, like if it is bounded by a certain function, or its convergence rate or competitiveness ratio.\n",
    "\n",
    "**Convergence Rate**: How quickly an algorithm approaches a desired solution or equilibrium state. Often expressed as a function of the number of iterations or time taken. Typically, a faster convergence rate suggests a more efficient and accurate algorithm.\n",
    "\n",
    "**Competitiveness Ratio**: A metric to evaluate online algorithms. It compares the algorithms performance to an optimal offline algorithm. It measures how much worse the online algorithms performs, a competitiveness ratio less than or equal to constant value indicates the the online algorithms performance is bounded relative to the optimal. A lower ratio generally implies a more efficient online algorithm.\n",
    "\n",
    "**Bounded**: a quantity or value that is contrained within certain limits. It implies that there exists a maximum or minimum value that the quantitiy can attain, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5371b-4955-4d41-9988-5b469e28db9c",
   "metadata": {},
   "source": [
    "## ***Lecture Notes*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2470dbf-94ab-4738-8e2d-36ba84808648",
   "metadata": {},
   "source": [
    "Analogy for mistake-bounded model: \n",
    "\n",
    "    Image an email spam filtering program that had the 100% guarantee that it would only mislabel 100 emails. No matter if you have 30 emails or 30,000 emails in your inbox, the program will only make 100 mistakes.\n",
    "\n",
    "---\n",
    "\n",
    "In this model we have a <b>\"Learner\"</b>, which takes in data points. Once it receives a data point, it responds with its guess for the classification of that data point. There is also the <b>\"Teacher\"</b>, which responds to the classification guess with whether the guess was correct or incorrect. When the Teacher tells the Learner that it made a mistake, a counter for the number of mistakes increases by one. However, also when the Learner makes a mistake, it learns from the mistake, updating its internal state.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.1.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "We say a Learner has mistake-bound <i>t</i> if for every sequence of challenges, Learner makes at most <i>t</i> mistakes.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**ùíû (Script C) definition:**\n",
    "<br>ùíû = {monotone disjunctions on n variables} \n",
    "<br>&emsp;&emsp;*English: Script C is equal to the set of all monotone disjunctions on n variables*\n",
    "<br>&emsp;&emsp;*(Note: Called monotone because there are no negations.)*\n",
    "<br>Domain = {0,1}<sub>n</sub> \n",
    "<br>&emsp;&emsp;*English: Domain is equal to the set of 0, 1 to the n (i.e., bit strings of length n)*\n",
    "\n",
    "Some functions in ùíû:\n",
    "- x1 ‚à® x3 - *Evaluates to 1 when given a bit string that has a one in the first or third position.*\n",
    "- f(x) = x1 ‚à® x7 ‚à® x9 - *Evaluates to 1 when given a bit string that has a one in the first, seventh, or ninth position.*\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.1.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "*f* ‚àà ùíû, so *f* is a monotone disjunction. The Learner does not know that *f* is a monotone disjunction. The Learner is fed a string in the domain, and responds with a 0 or a 1. The Teacher then responds with \"correct\" if the guess equals f(x), or \"mistake\" otherwise.\n",
    "\n",
    "If the Learner is giving a guess, 0 or 1, and the guess equals f(x), then nothing happens and the Learner moves on to the next input. If the Teacher replies that the guess was a mistake, then the Learner will update its state and recieve another input. \n",
    "\n",
    "In either case, the Learner is learning something. If the Learner was correct, it learned that it knew f(x). If it was incorrect, it still knows f(x) because f(x) is simply the opposite of the response the learner had given.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.1.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question:\n",
    "Can you come up with a Learner/algorithm with mistake bound at most *n*?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade65bd9-fc0b-4ead-826b-be46b6a8612a",
   "metadata": {},
   "source": [
    "## ***Book Notes*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700a265-45b8-4ea1-8f08-b22dbfb3a13d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a407302-2365-4e76-8d58-c6233749669b",
   "metadata": {},
   "source": [
    "## ***Resources*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95a5ac-36e9-4d88-a609-5e36dd9e56fa",
   "metadata": {},
   "source": [
    "**[On-line Algorithms in Machine Learning](C:\\Users\\laesc\\OneDrive\\Documents\\college\\ut%20austin\\machine%20learning\\4%20-%20resources\\online-algorithms-in-machine-learning.pdf)** (Local link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35064c2a-76f7-4496-8e7c-1c02b9fcf8e1",
   "metadata": {},
   "source": [
    "# **1.2 Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d34189-8b10-432a-9c47-b696e1134afa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ***Notes*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86424282-b5cc-457e-998b-b43f9e358b47",
   "metadata": {},
   "source": [
    "A decision tree is a boolean function (outputs true or false). At each node in the decision tree, there is a literal. At the leaves there is a fixed value which is the output.\n",
    "\n",
    "The size of the decision tree will be the number of nodes in the tree. The depth (height) of the tree is equal to the length of the longest path from the root to a leaf.\n",
    "\n",
    "*Note that for an input going into a decision tree, the x is referred to as a \"challenge\", and the y a \"label\".*\n",
    "\n",
    "Topics:\n",
    "- Heuristics for learning decision trees\n",
    "- Theoretical properties\n",
    "\n",
    "---\n",
    "\n",
    "**Example input: X ‚àà {0, 1}<sup>n</sup> (bit string of n length)**\n",
    "\n",
    "The decision tree is going to encode some function f(x) into {0, 1} as follows:\n",
    "\n",
    "- At each node, the tree decides which branch to take based on the value of the literal, until it reaches the leaf.\n",
    "\n",
    "The example decision tree's depth = 2, and size = 3.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.2.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### The machine learning problem:\n",
    "- Given a set of labeled examples, build a tree with low error\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**’è** = training set, where ’è is a collection of strings and 0, 1 labels.\n",
    "\n",
    "- So c is a collection of X's and y's, where X ‚àà {0, 1}<sup>n</sup>, and y ‚àà {0, 1}.\n",
    "<br>\n",
    "\n",
    "**Error Rate/Training Error/Emperical Error Rate** = (number of mistakes that T makes on ’è)/ size of ’è, where T is a decision tree.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.2.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Natural approach for building decision trees:\n",
    "- Given a set ’è\n",
    "\n",
    "<br>\n",
    "\n",
    "- Tree 1: Very simple, trivial tree\n",
    "    - Tree is a leaf (we dont query any literals, always output 0 or 1)\n",
    "    - How do we decide what to output?\n",
    "        - Choose 1 or 0 depending on which label is more prevalent in the dataset\n",
    " <br>\n",
    "     \n",
    "- Tree 2: More advanced tree\n",
    "    - Tree has one node, the root\n",
    "    - How do we decide which literal to put at the root?\n",
    "        - You want a literal at the root that is going to discriminate between zero and one labels\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.2.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### So how do we decide which literal to put at the root?\n",
    "\n",
    "Define a potential function Œ¶(a):\n",
    "<br>&emsp;&emsp;*[English: phi of a]*\n",
    "\n",
    "$$Œ¶(a) = min(a, 1-a)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "So, for the trivial decision tree:\n",
    "\n",
    "Pick a literal, *x<sub>i</sub>* , then compute Œ¶(Pr<sub>(x, y)~’è</sub> (y = 0))\n",
    "<br>&emsp;&emsp;*[English: Compute phi of the probability that for an example we choose from ’è that y = 0]*\n",
    "\n",
    "- Assume: 10 positive examples\n",
    "- Assume: 5 negative examples\n",
    "- What is Œ¶(Pr<sub>(x, y)~’è</sub> (y = 0))?\n",
    "    - 1/3\n",
    "- *This* probability is the error rate for the trivial decistion tree.\n",
    "\n",
    "$$ Œ¶(Pr_{(x, y)\\textasciitilde ’è} (y = 0)) $$\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.2.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Looking at the tree with one node, pick a literal, *x<sub>1</sub>*, as the root node...\n",
    "\n",
    "What label should be put on the first leaf?\n",
    "- Condition on *x<sub>1</sub>* = 0 -> output the majority value\n",
    "\n",
    "Then, for the second leaf...\n",
    "- Condition on *x<sub>1</sub>* = 1 -> output the majority value\n",
    "\n",
    "Meaning, for each option of the value of *x<sub>1</sub>*, we output the majority label for that value of *x<sub>1</sub>*.\n",
    "\n",
    "<br> \n",
    "\n",
    "**What is the new error rate?**\n",
    "\n",
    "It is a weighted average of the error of each of the new leaves. Explicitly written out, the error rate for the decision tree with one node is:\n",
    "\n",
    "$$\n",
    "Pr_{(x, y)\\textasciitilde’è}[x_1 = 0]*Œ¶(Pr_{(x, y)\\textasciitilde ’è} (y = 0) | x_1 = 0) + \n",
    "Pr_{(x, y)\\textasciitilde ’è}[x_1 = 1]*Œ¶(Pr_{(x, y)\\textasciitilde ’è} (y = 0) | x_1 = 1)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Gain(x<sub>1</sub>) = Old Rate - New Rate using x<sub>1</sub>**\n",
    "<br>&emsp;&emsp;*[English: The gain of x<sub>1</sub> is the old error rate minus the new error rate using x<sub>1</sub>]*\n",
    "\n",
    "This is the gain in training error that we attained by moving from the trivial decision tree to the decision tree where we put x<sub>1</sub> at the root. We are defining it as Gain(x<sub>1</sub>).\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.2.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Now we can compute the Gain(x<sub>i</sub>) of each literal, from x<sub>1</sub> to x<sub>n</sub>, and find which literal maximizes the gain and place that literal at the root of our tree. \n",
    "\n",
    "Once we have done that, each branch will now be using a subset of the original set. In this case the left branch will use the training set ’è<sub>|x<sub>1</sub>=0</sub> *[English: ’è restricted to x<sub>1</sub>=0]*, and the right branch will be using the training set ’è<sub>|x<sub>1</sub>=1</sub> *[English: ’è restricted to x<sub>1</sub>=1]*. \n",
    "\n",
    "Meaning we have two different training sets now, one for the left subtree and one for the right subtree. We repeat the process of computing what literal should be at the root of the next subtrees and continue until the tree has been completed.\n",
    "\n",
    "Is this computationally feasible?\n",
    "\n",
    "    It depends on what the functions are. In this case, the gain function is relatively easy to compute, but also consider how large of a tree that you want to build. Also, if you start building trees that are extremely or exponentially large in terms of the features we have, that is not going to be computationally feasible. So we are going to need some sort of stopping criterion. The stopping criterion will be covered later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79ca8b-7cc8-4232-b233-9c11ef880aff",
   "metadata": {},
   "source": [
    "## ***Resources*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5919c6-0c0c-49c2-891e-b5d05b61e643",
   "metadata": {},
   "source": [
    "**[Understanding Machine Learning: From Theory to Algorithms, Chapter 18](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)** (Internet link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc20d8-6acc-44e4-a745-d8e8506ece47",
   "metadata": {},
   "source": [
    "# **1.3 Generalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c260d-daa1-4684-9a56-f59a6ca1e6f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ***Notes*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a340480-7fb0-4950-ab70-4ce8ab625edf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.3.0 Introduction to Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab1bd7-f737-4f80-9f71-c7c497e372fe",
   "metadata": {},
   "source": [
    "#### **Generalization, or predictive power of a classifier.**\n",
    "\n",
    "What we want to understand is how well the classifier we built is going to perform when it is given data that it has not seen before. We would like to estimate this generalization error and understand when it is going to have good generalization error. This is going to lead us to the PAC model of learning, which is a foundational model of learning.\n",
    "\n",
    "- What is the \"true error\" or generalization error of a classifier?\n",
    "- Decision trees:\n",
    "    - Let us fix some tree T, created based on the rules we created above.\n",
    "    - And let us say we have a probability distribution D on new examples. \n",
    "    - So for a new challenge and a new label, and we want to know what is:\n",
    "\n",
    "$$Pr_{(x, y)\\textasciitilde D}[T(x) \\neq y]$$\n",
    "\n",
    "<br>*[English: The probability that when we randomly draw a challenge from some unknown distribution D, T(x) does not equal y]*\n",
    "\n",
    "We call this the **true error**, or generalization error, of T. Of course, we are hoping that this quantity is small.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **So when might this quantity not be small?**\n",
    "\n",
    "Let us imagine that we have a training set ’è, where we have challenges x<sup>1</sup> through x<sup>m</sup>, and labels y<sup>1</sup> through y<sup>m</sup>., where x<sup>i</sup>‚àà{0,1}<sup>n</sup> and y<sup>i</sup>‚àà{0,1}. Assume all x<sup>i</sup> are distinct.\n",
    "\n",
    "A learner is given ’è, and provides the classifier that is an exact copy of the training set. In this case, the learner is memorizing the training set. No real learning has occured, and unless ’è is the entire set of all possible inputs, this is a bad classifier. \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Let us again consider a case with training set ’è as described before. We can build a decision tree at least of the size of ’è, that is consistent with all the points in ’è. \n",
    "\n",
    "**Then the question is: *How well does this tree generalize?* or, *What is the true error of this tree?***\n",
    "\n",
    "It will be pretty bad, qualitatively, because it is simply memorizing every entry in the training set.\n",
    "\n",
    "In our decision trees, we only considered having a low training error. To create a robust tree that can handle real data, we also need to consider, are we getting true low generalization error? We want a good combination of both things.\n",
    "\n",
    "---\n",
    "\n",
    "#### **How can we estimate the true error of a decision tree?**\n",
    "\n",
    "A **\"hold-out\"** or **\"validation set\"** is used for this purpose.\n",
    "\n",
    "The idea is that we have ’è, the training set, and then we will have some more data that we will not let the decision tree look at, called ·ïº, our hold out.\n",
    "\n",
    "1. Use ’è to build a decision tree\n",
    "2. Estimate the tree's true error via its error on ·ïº\n",
    "\n",
    "By counting the number of mistakes that our tree makes on ·ïº, we will compute the error rate of the tree on ·ïº, and we'll use that for the estimate of the true error. As long as ·ïº is suffiently large, for any fixed tree we have built using ’è, the estimate of its true error will be very close to its error on ·ïº, which is something you can prove.\n",
    "\n",
    "It is important that you do not go back to the tree and modify it over and over to reduce error on ·ïº, because at that point you are now incorporating the validation set into the tree with ’è. This would be considered **over-fitting**.\n",
    "\n",
    "It is also important to consider that hold-out sets can be expensive, especially if you create many models and larger models.\n",
    "\n",
    "To combat this, we can use a technique called **cross-validation**, which allows you to reuse data that has been held out in a validation set. This will be covered later.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bee75e-e64a-477d-aba0-b604fd693623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.3.1 Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb1ad2-f5b3-4042-8532-fd4a06686b6c",
   "metadata": {},
   "source": [
    "#### **Trading Training Error for Model Complexity** ####\n",
    "\n",
    "Another approach to estimate the true error of a decision tree is trade off training error with \"model complexity\".\n",
    "\n",
    "We can define another potential function, phi, where phi will map tree to real numbers. A common mapping is, given a training set ’è:\n",
    "\n",
    "$$ \\phi(T) = training\\;error\\;on\\;’è + \\alpha * \\frac{size(T)}{|S|} $$\n",
    "\n",
    "&emsp;*[Englsh: phi of T will output the training error on ’è + some value alpha * the size of T, divided by the size of ’è]*\n",
    "\n",
    "The alpha is often referred to as a hyperparameter, it is set in the beginning of the training.\n",
    "\n",
    "The goal is to minimize phi, and there are two ways that phi can increase.\n",
    "- Large training error on ’è\n",
    "- Tree is large in size\n",
    "\n",
    "Therefore, we can choose a tree that minimizes the potential function.\n",
    "\n",
    "**Because the size of the tree will be large when memorizing the training set, by balancing a reasonably small training error with a reasonably small tree, we can create a good tree.**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **Minimum Description Length** ####\n",
    "\n",
    "Another common approach is MDL, **minimum desciption length principle**. Again, given a training set and some number of bits needed to encode ’è, an upper bound would be $m*n(+1)$, m for the number of examples in the training set, n for the example x, and 1 for the label. We can then build a tree T. Let's say T is correct on 90% of ’è, and incorrect on 10%. We can encode ’è using \n",
    "\n",
    "$$bits(T) + \\#bits\\;to\\;encode\\;remaining\\;10\\%\\;wrong$$ \n",
    "\n",
    "*[English: the number of bits needed to encode T, the tree, plus the number of bits needed to encode the remaining 10% we got wrong]*.\n",
    "\n",
    "Recall: A bad learner is one that takes the training set and hands it back to you. What this is trying to capture is a notion of compression, how well can you compress the data given. We can encode it using just this tree and the bits required to encode the remaining 10% of the training set. So, the tree with the smallest MDL, is the better tree.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Classifying trees based on generalization error** ####\n",
    "- MDL\n",
    "- Trading off training error and tree size\n",
    "- Validation set\n",
    "- Cross-validation\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18827800-a4e9-4464-b665-46fc3c28185d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.3.2 PAC Model of Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556a66a-0fed-4d32-b778-5537b8d6c875",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Consider a distribution D on {0, 1}<sup>n</sup>, our domain, a function class C:\n",
    "\n",
    "$$ C = {decision\\;trees\\;of\\;size\\;S} $$\n",
    "\n",
    "and fix c ‚àà C, where c is the unknown decision treewe want to learn.\n",
    "\n",
    "---\n",
    "\n",
    "Learner that runs in polynomial-time. The learner recieves an example $(x, y)$, where $x \\textasciitilde D$ and $y=c(x)$. *[English: x is drawn according to the probability distribution D, and y is equal to c(x)]* The learner can request a new draw at any time, from x<sup>1</sup>, y<sup>1</sup> through x<sup>m</sup>, y<sup>m</sup> and y<sup>i</sup> = c(x<sup>i</sup>). \n",
    "\n",
    "The goal is for the learner to output h, where h ‚àà C, with the following property:\n",
    "\n",
    "$$ Pr_{x\\textasciitilde D}[h(x) ‚â† c(x)] ‚â§ œµ $$\n",
    "\n",
    "*[English: The probabiliyt that an x, from the distribution script D, that h(x) does not equal c(x), should be at most epsilon.]*\n",
    "\n",
    "Think of œµ being something small, like .01. The learner should be efficient. We had a parameter n (from the domain), and a parameter s (the size of the tree). The learner should always run in the time polynomial in n and s. And the number of samples, or draws, that the learner can request should also be bounded by a polynomial in n and s. (Becuase it takes one time step to take a draw from the distribution).\n",
    "\n",
    "The real goal is to output some hypothesis (classifier), h, whose true error is at most ‚àà.\n",
    "\n",
    "This is different from the mistake bounded model of learning, because that only required a bounded number of mistakes. Here we talk about probabilities, distribution, and is a little more complicated.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.7.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **Formalizing it:** ####\n",
    "\n",
    "    With probability (over the draws from D) at least 1 - Œ¥ [one minus delta], the learner should output a hypothesis h such that \n",
    "\n",
    "$$ Pr_{x\\textasciitilde D}[h(x) ‚â† c(x)] ‚â§ œµ $$\n",
    "\n",
    "    And the running time, which includes the draws it may take, should be \n",
    "\n",
    "$$ run-time = polynomial(\\frac{1}{œµ}, \\frac{1}{s}, n, s) $$\n",
    "\n",
    "&emsp;*[English: some polynomial in one over epsilon, one over delta, n, and s]*\n",
    "\n",
    "That is the formal statement of the goal of the learner.\\\n",
    "\n",
    "#### **Why do we need the probability at least 1 - Œ¥?** ####\n",
    "\n",
    "Imagine that the learner keeps requesting new draws from the distribution, and gets really unlucky and all the x's it draws are equal. It gets the same example over and over. We cannot expect the learner in this case to putput a classifier that has small error. Thus, we have to allow for some probability of failure. Luckily the probability of drawing the same example over and over is extremely small\\\n",
    "\n",
    "\n",
    "#### **What does PAC mean?**\\ ####\n",
    "\n",
    "P - probably - $ probability\\;at\\;least\\;1 - Œ¥ $\\\n",
    "A - approximately - $ Pr_{x\\textasciitilde D}[h(x) ‚â† c(x)] ‚â§ œµ $\\\n",
    "C - correct \n",
    "\n",
    "<br>\n",
    "\n",
    "Note: As you demand more accuracy, or smaller œµ, then you're allowed to run in more time and take more samples.\n",
    "\n",
    "This would work for any class of functions that output boolean values, not just decision trees. I.e. for any classification problem.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.8.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### ** When can we PAC learn a function class? ** ####\n",
    "\n",
    "Or, what function classes can we PAC learn?\n",
    "\n",
    "Give learner an algorithm A, which maps training sets to decision trees...\n",
    "\n",
    "A on a training set S will output a tree T that is consistent with S. Furthermore, the size of T is going to be at most s.\n",
    "\n",
    "So, A always outputs a consistent hypothesis from C given any training set (assuming there is one).\n",
    "\n",
    "Question: *Given algorithm A, how can we PAC learn C*?\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.9.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**High level algorithm**: Draw sufficiently many training points (which we will call S), use A to find a function (c) in C consistent with S, then output c.\n",
    "\n",
    "The only question left is *how large should S be*? (Recall that the PAC learning model must run in polynomial time in terms of the parameters, drawing exponentially many points will not do)\n",
    "\n",
    "    Illustrative example: Marble Game\n",
    "    \n",
    "    Jar 1: all blue marbles\\\n",
    "    Jar 2: 90% red marbles, 10% blue marbles\\\n",
    "    \n",
    "    Figure out if you've been given Jar 1 or Jar 2, given a random element of the jar any time you want. \n",
    "    \n",
    "    - Pick a random marble from the jar:\n",
    "        - Case 1: the marble is red -> We have Jar 2\n",
    "        - Case 2: the marble is blue -> Probably Jar 1\n",
    "            - Choose at most 100 marbles\n",
    "                - If we see red, then Jar 2, if not then choose jar 1.\n",
    "             \n",
    "    **What is the probability of failure?**\n",
    "    \n",
    "    Probability of failure is (.1)<sup>100</sup>, which corresponds to the Œ¥ parameter in PAC learning.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.10.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Back to PAC learning:\n",
    "- Draw many samples\n",
    "- Run A\n",
    "- Output classifier c that is consistent with S given from A\n",
    "\n",
    "What is the probability this procedure fails? \n",
    "\n",
    "And what do we want the above probability to be less than? Œ¥\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.11.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "The bad event, or failure, is we output c that is consistent with S, but the true error of c is greater than œµ. So, *what is the probability of this bad event*?\n",
    "\n",
    "Imagine we have enumerated all functions in C = {c<sub>1</sub>, ..., c<sub>N</sub>}. Fix c<sub>1</sub>, assume c<sub>1</sub> has true error > œµ (we do not want it, true error too high).\n",
    "\n",
    "What is $ Pr_S\\;[c_1\\;is\\;consistent\\;with\\;S] $?\n",
    "\n",
    "$$ Pr_S\\;[c_1\\;is\\;consistent\\;with\\;S] \\le (1-\\epsilon)^{|S|}$$\n",
    "\n",
    "Now, let's fix c<sub>2</sub>, assume c<sub>2</sub> has true error > œµ (we do not want it, true error too high). What is the same probability? Also $ Pr_S\\;[c_1\\;is\\;consistent\\;with\\;S] \\le (1-\\epsilon)^{|S|}$.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.12.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "For every c<sub>i</sub> (with error > œµ): $ Pr_S\\;[c_i\\;is\\;consistent\\;with\\;S] \\le (1-\\epsilon)^{|S|}$.\n",
    "\n",
    "Question: Randomly form S, what is the probability there even exists a function c whose error is > œµ and is consistent with S?\n",
    "\n",
    "Hint:\n",
    "\n",
    "    Union bound: Given A, B Pr[A ‚à® B] ‚â§ Pr[A] + Pr[B]\n",
    "    *The probability that A or B occurs is less than or equal to the probability that A occurs plus the probability that B occurs*\n",
    "\n",
    "Answer: $Pr[Bad\\;Event] \\le |C|*(1-\\epsilon)^{|S|}$, since there are at most C functions to consider and the probability of failure for each was $(1-\\epsilon)^{|S|}$. Recall, we wanted Pr[Bad Event] < Œ¥, so the goal is \n",
    "\n",
    "$$ Pr[Bad\\;Event] \\le |C|*(1-\\epsilon)^{|S|} \\le \\delta $$\n",
    "\n",
    "The only unknown variable is |S|, so we will solve for it.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.13.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Solving for |S|**\n",
    "\n",
    "$|C|*(1-\\epsilon)^{|S|} \\le \\delta$\\\n",
    "\n",
    "$|C|*(e)^{\\epsilon|S|} \\le \\delta$ (using (1-x) ‚âà e<sup>-x</sup>)\\\n",
    "\n",
    "$(e)^{\\epsilon|S|} \\le \\frac{\\delta}{|C|}$\n",
    "\n",
    "$\\epsilon|S| \\le log(\\frac{\\delta}{|C|})$\n",
    "\n",
    "which yields:\n",
    "\n",
    "$$|S| \\ge \\frac{log(\\frac{\\delta}{|C|})}{\\epsilon}$$\n",
    "\n",
    "This is saying that if you choose number of training points larger than $\\frac{log(\\frac{\\delta}{|C|})}{\\epsilon}$, then with probability ‚â• (1-Œ¥), the function output c is 1-œµ accurate.\\\n",
    "\n",
    "Thus we have exactly computed the size of the training set S such that the output function c is 1-œµ accurate.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.3.14.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Since we assumed A would give a consistent hypothesis each time, that suggests that there is a \"consistent hypothesis\" approach to learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331c0b8-6949-4c9f-987c-ee3a1c096643",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ***Resources*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62afbdfa-73ca-46d7-ab00-667300bc0a8f",
   "metadata": {},
   "source": [
    "none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82ddc2-0f75-4304-81a2-ea4e6c68ee3c",
   "metadata": {},
   "source": [
    "# **1.4 PAC Learning** #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929afd4f-69d6-4779-a5c1-3beb76f3c2e7",
   "metadata": {},
   "source": [
    "## ***Notes*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd861a-4b3d-49fe-96a4-fba9bc369650",
   "metadata": {},
   "source": [
    "### 1.4.0 Infinite Function Class ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec14f81-f179-419a-ab15-afc1457d876e",
   "metadata": {},
   "source": [
    "**PAC-learning axis-parallel rectangles**\n",
    "\n",
    "We are working in two-dimensions. Axis-parallel rectangles implies the axes are parallel to the x and y axis.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.4.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**What is the learning problem?** We are going to be given points, and some will be labeled positive and some will be labeled negatvie. Positive label means the point is inside c, an unknown axis-parallel rectangle. Negative labels mean the point is outside c, the unknown axis-parallel rectangle.\n",
    "\n",
    "**Goal**: given $\\epsilon$, $\\delta$ output h that is $\\epsilon$ accurate with probability $\\ge$ 1-$\\delta$.\n",
    "\n",
    "    Recall in 1.3.2 we used A which produced a consistent result (the consistency algorithm), because that depended on the size of the function class, |C|. In this case we have infinitely many axis-parallel rectangles. \n",
    "\n",
    "We will claim that the tightest fitting rectangle will solve this problem.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.4.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Claim**: Tightest fitting rectangle works for this problem\\\n",
    "**Question**: How large to choose our training set (|S|) \n",
    "\n",
    "**What is a bad event in this case?** The positive points are clustered around some tiny rectangle that is very small with respect to the true rectangle. I.e., lots of probability mass exists outside of h. If the probability of landing in that probability mass is at least $\\epsilon$ then we are in trouble.\n",
    "\n",
    "How do we bound the probability this happens?\n",
    "\n",
    "Let's analyze h (the tightest fitting rectangle), and say something about h vs. all the rectangles that are large and contain h (the bad events). Since there are pretty much infinitely many bad events, then this will be hard to analyze. \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.4.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "If neither B<sub>1</sub>, B<sub>2</sub>, B<sub>3</sub>, or B<sub>4</sub> occur (see image below), then h (the tightest fitting rectangle) is $\\epsilon$ accurate.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.4.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**We still need to figure out how large we want |S| to be.**\n",
    "\n",
    "If we choose m random samples, what is Pr[B<sub>1</sub>]?\n",
    "- $Pr[B_1] \\le (1-\\frac{\\epsilon}{4})^m$\n",
    "\n",
    "Then, by that logic:\n",
    "\n",
    "$$ Pr[B_1 \\lor B_2 \\lor B_3 \\lor B_4] \\le 4(1-\\frac{\\epsilon}{4})^m \\le \\delta$$\n",
    "\n",
    "And solving that inequality (step 3 using 1+x ‚âà e<sup>x</sup>, so 1-x ‚âà e<sup>-x</sup>:\n",
    "\n",
    "$$ 4(1-\\frac{\\epsilon}{4})^m \\le \\delta $$\n",
    "\n",
    "$$ (1-\\frac{\\epsilon}{4})^m \\le \\frac{\\delta}{4} $$\n",
    "\n",
    "$$ e^{-\\frac{\\epsilon m}{4}} \\le \\frac{\\delta}{4} $$ \n",
    "\n",
    "$$ -\\frac{\\epsilon m}{4} \\le log(\\frac{\\delta}{4}) $$\n",
    "\n",
    "$$ m \\ge \\frac{4*log(\\frac{\\delta}{4})}{\\epsilon} $$\n",
    "\n",
    "So, as long as we choose a number of samples that is at least $\\frac{4*log(\\frac{\\delta}{4})}{\\epsilon}$, then we know that h, the tightest fitting rectangle, will be $\\epsilon$ accurate with probability $\\ge\\;1-\\delta$.\n",
    "\n",
    "**Correction**\n",
    "\n",
    "At around 28:30 of 1.4.0, $ m \\ge \\frac{4*log(\\frac{\\delta}{4})}{\\epsilon} $ should instead be $ m \\ge \\frac{4*log(\\frac{4}{\\delta})}{\\epsilon} $. Note the inversion of the expression inside the log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c5c99-ae5f-44c5-8fe9-0189bf1172bb",
   "metadata": {},
   "source": [
    "### 1.4.1 Half Spaces ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ac1f7-4681-4a08-8c2b-68078254c0e3",
   "metadata": {},
   "source": [
    "Another interesting class to consider is C = {half spaces}. This is a function that takes in x and outputs sign(w*x-$\\theta$), where w $\\epsilon$ ‚Ñù<sup>n</sup>, x $\\epsilon$ ‚Ñù<sup>n</sup>, and $\\theta$) is a scalar (‚Ñù). \n",
    "\n",
    "The output f is boolean (0 or 1). The output is 0 if the result is zero or negative, and 1 if the result is positive.\n",
    "\n",
    "We can think of this result geometrically as dividing all of n-dimensional euclidean space into two half spaces.\n",
    "\n",
    "The goal is to come up with PAC learning algorithms for half spaces.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.4.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**One approach for learning half spaces**\n",
    "\n",
    "Recall that w is unknown, $\\theta$ is unknown, and the function we are trying to learn is equal to:\n",
    "\n",
    "$$f = sign(\\sum_{i=1}^{n} w_ix_i-\\theta) $$\n",
    "\n",
    "Draws are given from D of the form (x, f(x)), where x is distributed according to D. \n",
    "\n",
    "$$ (0 1 0 1 0, pos) \\Rightarrow w_2 + w_4 \\gt \\theta $$\n",
    "\n",
    "$$ (0 1 1 0, neg) \\Rightarrow w_2 + w_3 \\le \\theta $$\n",
    "\n",
    "Each labeled example corresponds to a linear inequality. Thus, we will get a system of linear inequalities. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Question:**\n",
    "- Can we find with consistent hypothesis?\n",
    "\n",
    "Let us assume that $ w_i\\;\\epsilon $ ‚Ñ§ in some bounded range. Now we can apply our consistency analysis, if we can come up with a consistent hypothesis.\n",
    "\n",
    "Given a system of inequalities, we can solve for a solution for the w<sub>i</sub>'s using a general purpose tool called **linear programming**. \n",
    "\n",
    "    Linear programming algorithms can be used to solve general systems of linear inequalities. Furthermore, these algorithms that solve linear programs are known to run in polynomial time.\n",
    "\n",
    "This will be covered later in class.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.4.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e089300-9384-40b9-b3d1-0d76728eec8c",
   "metadata": {},
   "source": [
    "## ***Resources*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764359b9-cce2-4fbb-9fc0-34812851e5dc",
   "metadata": {},
   "source": [
    "# 1.5 **Cross-Validation** #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acda26d0-e38b-46ca-a7ac-191da0cc3c48",
   "metadata": {},
   "source": [
    "## ***Notes*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a78a2-489f-42b3-b598-cceccd5a2f20",
   "metadata": {},
   "source": [
    "### Introduction ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2e528-af2b-4876-b238-04cd6a42bc7b",
   "metadata": {},
   "source": [
    "We will be looking at how to calculate the true error of a classifier model. \n",
    "\n",
    "Let's assume classification; so the hypothesis h is going to output boolean values (e.g., {0,1}, {-1,1}.\n",
    "\n",
    "- Hold-out approach (validation set) for testing/approximating the true error of a classifier\n",
    "    - Leave some part of the training set out during training time\n",
    "    - Then when you want to evaluate the true error of the classifier, you test the classifier on this held out set.\n",
    "    - The error on the held out set is the approximated true error for unseen data\n",
    " \n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Markov's Inequality**\n",
    "\n",
    "- Let x be a random variable that takes on only positive values\n",
    "- $Pr[x\\ge k*\\mathbf{E}[x]]\\le \\frac{1}{k}$\n",
    "    - *The probability that x is more than a factor of k times the expected value of x, is at most 1 over k*\n",
    " \n",
    "**Chebyshev's Inequality**\n",
    "\n",
    "- Review:\n",
    "    - Let us say $\\mathbf{E}[x]$ = $\\mu$ \n",
    "    - Review the variance of a random variable: $ Var[x] = \\mathbf{E}[(x-\\mathbf{E}[x])^2] $\n",
    "        - On average, how much does a draw of x deviate from its expectation or average squared\n",
    "    - Recall that $\\sqrt{Var[x]} = standard\\;deviation(x) = \\sigma$\n",
    " \n",
    "<br>\n",
    "\n",
    "If we have a random variable, we understand that its mean is $\\mu$, and its variance is $\\sigma$, the probability that the random variable x deviates from its expectation by more than t standard deviations, is less than or equal to one over t<sup>2</sup>.\n",
    "\n",
    "$$ Pr[|x-\\mu| \\gt t*\\sigma] \\le \\frac{1}{t^2} $$\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6aaa05-1c66-4f8e-8ae3-638143b1f153",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Chernoff Bound ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebdb21-a07e-4879-a98c-9154734026cd",
   "metadata": {},
   "source": [
    "Let's say we have random variables $x_1, x_2, ..., x_n$, $x_i \\epsilon \\{0,1\\}$ and that $\\mathbf{E}[x_i] = p$ (the chernoff bound holds for $\\mathbf{E}[x_i] = p_i$, but we are fixing to p for simplicity). \n",
    "\n",
    "We also have \n",
    "\n",
    "$$S = \\sum_{i=1}^{n} x_i $$\n",
    "\n",
    "Also let $\\mathbf{E}[S]$ = $\\mu$ = $p*n$, in other words $\\mathbf{E}[x_1+...+x_n] = p*n$\n",
    "\n",
    "The Chernoff Bound says:\n",
    "\n",
    "$$ Pr[S>\\mu +\\delta n] \\le e^{-2n\\delta^2} $$\n",
    "\n",
    "$$ Pr[S<\\mu -\\delta n] \\le e^{-2n\\delta^2} $$\n",
    "\n",
    "$$ \\Rightarrow Pr[|S-\\mu| > \\delta n] \\le 2e^{-2n\\delta^2} $$\n",
    "\n",
    "Basically, when you have a bunch of independent random variables, each ones mean is p and you take the sum of them, you would expect the sum to be about p * n, so this is the expectation of S, the sum. What that Chernoff Bound says is that the probability that your sum S deviates from $\\mu$ is actually exponentially small in the quantity n.\n",
    "\n",
    "\"The probability that I deviate more than $\\delta$n is exponentially small in n, and depending on my choice of $\\delta$ I will be getting different bounds for these probabilities.\" \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Applying the Chernoff Bound to the case of estimating the true error of a classifier...\n",
    "\n",
    "We have hold-out set S, and we'll say the |S| = n (the size of S is n).\\ \n",
    "Fix h (generated using some independent training set). Recall that there is some underlying distribution D from which we are generating training points, and that S is a sample drawn from D independent of the trianing set.\n",
    "\n",
    "$$ Z = Pr_{x\\textasciitilde D}[h(x) \\ne c(x)] $$\n",
    "\n",
    "where c is the unknown function we are trying to learn, and h is the classifier that we've generated and want to understand its true error, which is Z.\n",
    "\n",
    "What random variable should we define if we want to use the Chernoff Bound...?\n",
    "\n",
    "Let $x_i$ be the random variable that equals 1 if h is incorrect on the i<sup>th</sup> element of S. It will be 0 if h is correct on the i<sup>th</sup> element of S.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "So we have random variables $x_1, x_2, ..., x_n$, and \n",
    "\n",
    "$$ x_i = \\begin{cases} \n",
    "          1\\;if\\;h\\;is\\;correct\\;on\\;i^{th}\\;element \\\\\n",
    "          0\\;otherwise \n",
    "          \\end{cases}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$S = \\sum_{i=1}^{n} x_i $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\mathbf{E}[S] = n*p $$\n",
    "\n",
    "where p is actually the true error of h, because p is the expected value of $x_i$, and $x_i$ outputs 1 when incorrect.\n",
    "\n",
    "$$ Pr[|S - n*p| > \\delta n] \\le 2e^{-2n\\delta^2} $$\n",
    "\n",
    "(Recall p is the true error of classifier h)  \n",
    "\n",
    "Say we set $\\delta$ = .1, then $ Pr[|S - n*p| > .1n] \\le 2e^{\\frac{-2n}{100}}$ \n",
    "\n",
    "I will call the quantity $ 2e^{\\frac{-2n}{100}} $ from the above inequality the confidence parameter. \n",
    "\n",
    "How large do we need to take n before the confidence parameter becomes smaller than some small quantity $\\alpha$? \n",
    "\n",
    "$$ 2e^{\\frac{-2n}{100}} \\lt \\alpha $$\n",
    "$$ e^{\\frac{-2n}{100}} \\lt \\frac{\\alpha}{2} $$\n",
    "$$ \\frac{-2n}{100} \\lt log(\\frac{\\alpha}{2}) \\Rightarrow n \\gt 50*log(\\frac{2}{\\alpha})$$ \n",
    "\n",
    "So if we want the probability of failure to be less than alpha, and we want to be confident that our estimate is within .1\\*n, then we need n to be $ 50*log(\\frac{2}{\\alpha}) $\n",
    "\n",
    "Notice: if $ |S-n*p| \\le .1n \\Rightarrow error\\;rate\\;on\\;S\\;is\\;within\\;.1\\;of\\;true\\;error\\;rate $\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88d690-ecc1-47b9-85e2-d253dba342ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### How it Works ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00663918-6609-4670-b099-473bb441a87e",
   "metadata": {},
   "source": [
    "The hold-out set is somewhat expensive..\n",
    "- Data is expensive or difficult to obtain, and we arent using it for training the classifier\n",
    "- If we want to try out multiple methods for generating classifiers, we quickly lose confidence in our estimates (however many times you use the hold out set you must multiply alpha). This gets expensive when testing different classifiers and parameter settings.\n",
    "\n",
    "How can we build lots of understand the true error of many different classifiers that we generate? How can we reuse our training set to build different classifiers and still understand our true error? Still an open problem in the field, but best current solution is cross-validation.\n",
    "\n",
    "Cross-validation works very well in practice, and is used in packages such as scikit-learn. \n",
    "\n",
    "---\n",
    "\n",
    "The idea behind cross validation is that we are going to take our entire training set and break it up into *folds*. We will then use the training set to at the same time train the classifier and calculate the true error.\n",
    "\n",
    "First we'll hold out fold 1 and train using folds 2 thorugh fold k. We will then test on fold 1, and that will be our estimate for that classifiers true error.\n",
    "\n",
    "Then, we'll hold out fold 2 and train using fold 1 and fold 3 through fold k. We will the test on fold 2, and that will be our estimate for the true estimate for that classifier. \n",
    "\n",
    "We will do this k times, once for each fold, and we will average all the errors that we got. That will be the estimate for the true error of a classifer produced with the parameters used to build the model.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Let's use decision trees for an example. We have a training set S, and are trying to decide:\n",
    "- Should I build a decision tree of depth 10 or depth 15?\n",
    "\n",
    "We decide using cross-validation...\n",
    "\n",
    "We create the folds in our training set and set depth = 10. We leave out fold 1 and build a decision tree with depth 10, and test the accuracy on fold 1. Then we'll hold out fold 2 and do the same thing. We will repeat for all folds and take the average of their error rates, which will provide and estimate of the true error for the decision tree of depth 10.\n",
    "\n",
    "Then, we will do the exact same thing, but set the depth parameter to 15 this time. We will end up with the estimate for the true error for the tree with depth 15. \n",
    "\n",
    "Whichever error is smaller would be the tree we want to use!\n",
    "\n",
    "---\n",
    "\n",
    "Question: What should k be set to?\n",
    "- Between 5 and 10 is typically what is used.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"1.5.7.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee4278-3683-4dbb-bada-043e84736cd5",
   "metadata": {},
   "source": [
    "## ***Resources*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e461cb3-0be0-4b72-a15f-be137846c497",
   "metadata": {},
   "source": [
    "**[Understanding Machine Learning: From Theory to Algorithms, Chapter 3](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)** (Internet link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
