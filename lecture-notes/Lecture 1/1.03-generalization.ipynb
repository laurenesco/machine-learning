{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be158dc-a876-43cb-9c39-279dd11cea45",
   "metadata": {},
   "source": [
    "# Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41c711-1504-4cd0-93a3-aa8a6963a859",
   "metadata": {},
   "source": [
    "## ***Vocabulary***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ceb54-7137-431e-8ae1-1053d0f2bcbe",
   "metadata": {},
   "source": [
    "none yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc47029-8dd1-4934-8f85-9487837b1e2c",
   "metadata": {},
   "source": [
    "# Lecture Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eb618-a347-4dd5-bb64-a4efac8cacf4",
   "metadata": {},
   "source": [
    "## ***Introduction***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2ec31-1e8c-44c3-bb67-c6f2b821879c",
   "metadata": {},
   "source": [
    "#### **Generalization, or predictive power of a classifier.**\n",
    "\n",
    "What we want to understand is how well the classifier we built is going to perform when it is given data that it has not seen before. We would like to estimate this generalization error and understand when it is going to have good generalization error. This is going to lead us to the PAC model of learning, which is a foundational model of learning.\n",
    "\n",
    "- What is the \"true error\" or generalization error of a classifier?\n",
    "- Decision trees:\n",
    "    - Let us fix some tree T, created based on the rules we created above.\n",
    "    - And let us say we have a probability distribution D on new examples. \n",
    "    - So for a new challenge and a new label, and we want to know what is:\n",
    "\n",
    "$$Pr_{(x, y)\\textasciitilde D}[T(x) \\neq y]$$\n",
    "\n",
    "<br>*[English: The probability that when we randomly draw a challenge from some unknown distribution D, T(x) does not equal y]*\n",
    "\n",
    "We call this the **true error**, or generalization error, of T. Of course, we are hoping that this quantity is small.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **So when might this quantity not be small?**\n",
    "\n",
    "Let us imagine that we have a training set Տ, where we have challenges x<sup>1</sup> through x<sup>m</sup>, and labels y<sup>1</sup> through y<sup>m</sup>., where x<sup>i</sup>∈{0,1}<sup>n</sup> and y<sup>i</sup>∈{0,1}. Assume all x<sup>i</sup> are distinct.\n",
    "\n",
    "A learner is given Տ, and provides the classifier that is an exact copy of the training set. In this case, the learner is memorizing the training set. No real learning has occured, and unless Տ is the entire set of all possible inputs, this is a bad classifier. \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Let us again consider a case with training set Տ as described before. We can build a decision tree at least of the size of Տ, that is consistent with all the points in Տ. \n",
    "\n",
    "**Then the question is: *How well does this tree generalize?* or, *What is the true error of this tree?***\n",
    "\n",
    "It will be pretty bad, qualitatively, because it is simply memorizing every entry in the training set.\n",
    "\n",
    "In our decision trees, we only considered having a low training error. To create a robust tree that can handle real data, we also need to consider, are we getting true low generalization error? We want a good combination of both things.\n",
    "\n",
    "---\n",
    "\n",
    "#### **How can we estimate the true error of a decision tree?**\n",
    "\n",
    "A **\"hold-out\"** or **\"validation set\"** is used for this purpose.\n",
    "\n",
    "The idea is that we have Տ, the training set, and then we will have some more data that we will not let the decision tree look at, called ᕼ, our hold out.\n",
    "\n",
    "1. Use Տ to build a decision tree\n",
    "2. Estimate the tree's true error via its error on ᕼ\n",
    "\n",
    "By counting the number of mistakes that our tree makes on ᕼ, we will compute the error rate of the tree on ᕼ, and we'll use that for the estimate of the true error. As long as ᕼ is suffiently large, for any fixed tree we have built using Տ, the estimate of its true error will be very close to its error on ᕼ, which is something you can prove.\n",
    "\n",
    "It is important that you do not go back to the tree and modify it over and over to reduce error on ᕼ, because at that point you are now incorporating the validation set into the tree with Տ. This would be considered **over-fitting**.\n",
    "\n",
    "It is also important to consider that hold-out sets can be expensive, especially if you create many models and larger models.\n",
    "\n",
    "To combat this, we can use a technique called **cross-validation**, which allows you to reuse data that has been held out in a validation set. This will be covered later.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ed5cd-43a9-4384-be36-0a59ee244e86",
   "metadata": {},
   "source": [
    "## ***Model Complexity***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb82a9-1780-4c14-9406-a59c82ba1d90",
   "metadata": {},
   "source": [
    "#### **Trading Training Error for Model Complexity** ####\n",
    "\n",
    "Another approach to estimate the true error of a decision tree is trade off training error with \"model complexity\".\n",
    "\n",
    "We can define another potential function, phi, where phi will map tree to real numbers. A common mapping is, given a training set Տ:\n",
    "\n",
    "$$ \\phi(T) = training\\;error\\;on\\;Տ + \\alpha * \\frac{size(T)}{|S|} $$\n",
    "\n",
    "&emsp;*[Englsh: phi of T will output the training error on Տ + some value alpha * the size of T, divided by the size of Տ]*\n",
    "\n",
    "The alpha is often referred to as a hyperparameter, it is set in the beginning of the training.\n",
    "\n",
    "The goal is to minimize phi, and there are two ways that phi can increase.\n",
    "- Large training error on Տ\n",
    "- Tree is large in size\n",
    "\n",
    "Therefore, we can choose a tree that minimizes the potential function.\n",
    "\n",
    "**Because the size of the tree will be large when memorizing the training set, by balancing a reasonably small training error with a reasonably small tree, we can create a good tree.**\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **Minimum Description Length** ####\n",
    "\n",
    "Another common approach is MDL, **minimum desciption length principle**. Again, given a training set and some number of bits needed to encode Տ, an upper bound would be $m*n(+1)$, m for the number of examples in the training set, n for the example x, and 1 for the label. We can then build a tree T. Let's say T is correct on 90% of Տ, and incorrect on 10%. We can encode Տ using \n",
    "\n",
    "$$bits(T) + \\#bits\\;to\\;encode\\;remaining\\;10\\%\\;wrong$$ \n",
    "\n",
    "*[English: the number of bits needed to encode T, the tree, plus the number of bits needed to encode the remaining 10% we got wrong]*.\n",
    "\n",
    "Recall: A bad learner is one that takes the training set and hands it back to you. What this is trying to capture is a notion of compression, how well can you compress the data given. We can encode it using just this tree and the bits required to encode the remaining 10% of the training set. So, the tree with the smallest MDL, is the better tree.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Classifying trees based on generalization error** ####\n",
    "- MDL\n",
    "- Trading off training error and tree size\n",
    "- Validation set\n",
    "- Cross-validation\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eefce1-6926-4e40-bb51-c850c23f3208",
   "metadata": {},
   "source": [
    "## ***PAC Model of Learning***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47367318-9c44-41f9-acd7-2a9cdf4fb012",
   "metadata": {},
   "source": [
    "Consider a distribution D on {0, 1}<sup>n</sup>, our domain, a function class C:\n",
    "\n",
    "$$ C = {decision\\;trees\\;of\\;size\\;S} $$\n",
    "\n",
    "and fix c ∈ C, where c is the unknown decision treewe want to learn.\n",
    "\n",
    "---\n",
    "\n",
    "Learner that runs in polynomial-time. The learner recieves an example $(x, y)$, where $x \\textasciitilde D$ and $y=c(x)$. *[English: x is drawn according to the probability distribution D, and y is equal to c(x)]* The learner can request a new draw at any time, from x<sup>1</sup>, y<sup>1</sup> through x<sup>m</sup>, y<sup>m</sup> and y<sup>i</sup> = c(x<sup>i</sup>). \n",
    "\n",
    "The goal is for the learner to output h, where h ∈ C, with the following property:\n",
    "\n",
    "$$ Pr_{x\\textasciitilde D}[h(x) ≠ c(x)] ≤ ϵ $$\n",
    "\n",
    "*[English: The probabiliyt that an x, from the distribution script D, that h(x) does not equal c(x), should be at most epsilon.]*\n",
    "\n",
    "Think of ϵ being something small, like .01. The learner should be efficient. We had a parameter n (from the domain), and a parameter s (the size of the tree). The learner should always run in the time polynomial in n and s. And the number of samples, or draws, that the learner can request should also be bounded by a polynomial in n and s. (Becuase it takes one time step to take a draw from the distribution).\n",
    "\n",
    "The real goal is to output some hypothesis (classifier), h, whose true error is at most ∈.\n",
    "\n",
    "This is different from the mistake bounded model of learning, because that only required a bounded number of mistakes. Here we talk about probabilities, distribution, and is a little more complicated.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.7.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **Formalizing it:** ####\n",
    "\n",
    "    With probability (over the draws from D) at least 1 - δ [one minus delta], the learner should output a hypothesis h such that \n",
    "\n",
    "$$ Pr_{x\\textasciitilde D}[h(x) ≠ c(x)] ≤ ϵ $$\n",
    "\n",
    "    And the running time, which includes the draws it may take, should be \n",
    "\n",
    "$$ run-time = polynomial(\\frac{1}{ϵ}, \\frac{1}{s}, n, s) $$\n",
    "\n",
    "&emsp;*[English: some polynomial in one over epsilon, one over delta, n, and s]*\n",
    "\n",
    "That is the formal statement of the goal of the learner.\\\n",
    "\n",
    "#### **Why do we need the probability at least 1 - δ?** ####\n",
    "\n",
    "Imagine that the learner keeps requesting new draws from the distribution, and gets really unlucky and all the x's it draws are equal. It gets the same example over and over. We cannot expect the learner in this case to putput a classifier that has small error. Thus, we have to allow for some probability of failure. Luckily the probability of drawing the same example over and over is extremely small\\\n",
    "\n",
    "\n",
    "#### **What does PAC mean?**\n",
    "\n",
    "P - probably - $ probability\\;at\\;least\\;1 - δ $\\\n",
    "A - approximately - $ Pr_{x\\textasciitilde D}[h(x) ≠ c(x)] ≤ ϵ $\\\n",
    "C - correct \n",
    "\n",
    "<br>\n",
    "\n",
    "Note: As you demand more accuracy, or smaller ϵ, then you're allowed to run in more time and take more samples.\n",
    "\n",
    "This would work for any class of functions that output boolean values, not just decision trees. I.e. for any classification problem.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.8.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **When can we PAC learn a function class?**\n",
    "\n",
    "Or, what function classes can we PAC learn?\n",
    "\n",
    "Give learner an algorithm A, which maps training sets to decision trees...\n",
    "\n",
    "A on a training set S will output a tree T that is consistent with S. Furthermore, the size of T is going to be at most s.\n",
    "\n",
    "So, A always outputs a consistent hypothesis from C given any training set (assuming there is one).\n",
    "\n",
    "Question: *Given algorithm A, how can we PAC learn C*?\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.9.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**High level algorithm**: Draw sufficiently many training points (which we will call S), use A to find a function (c) in C consistent with S, then output c.\n",
    "\n",
    "The only question left is *how large should S be*? (Recall that the PAC learning model must run in polynomial time in terms of the parameters, drawing exponentially many points will not do)\n",
    "\n",
    "    Illustrative example: Marble Game\n",
    "    \n",
    "    Jar 1: all blue marbles\\\n",
    "    Jar 2: 90% red marbles, 10% blue marbles\\\n",
    "    \n",
    "    Figure out if you've been given Jar 1 or Jar 2, given a random element of the jar any time you want. \n",
    "    \n",
    "    - Pick a random marble from the jar:\n",
    "        - Case 1: the marble is red -> We have Jar 2\n",
    "        - Case 2: the marble is blue -> Probably Jar 1\n",
    "            - Choose at most 100 marbles\n",
    "                - If we see red, then Jar 2, if not then choose jar 1.\n",
    "             \n",
    "    **What is the probability of failure?**\n",
    "    \n",
    "    Probability of failure is (.1)<sup>100</sup>, which corresponds to the δ parameter in PAC learning.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.10.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Back to PAC learning:\n",
    "- Draw many samples\n",
    "- Run A\n",
    "- Output classifier c that is consistent with S given from A\n",
    "\n",
    "What is the probability this procedure fails? \n",
    "\n",
    "And what do we want the above probability to be less than? δ\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.11.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "The bad event, or failure, is we output c that is consistent with S, but the true error of c is greater than ϵ. So, *what is the probability of this bad event*?\n",
    "\n",
    "Imagine we have enumerated all functions in C = {c<sub>1</sub>, ..., c<sub>N</sub>}. Fix c<sub>1</sub>, assume c<sub>1</sub> has true error > ϵ (we do not want it, true error too high).\n",
    "\n",
    "What is $ Pr_S\\;[c_1\\;is\\;consistent\\;with\\;S] $?\n",
    "\n",
    "$$ Pr_S\\;[c_1\\;is\\;consistent\\;with\\;S] \\le (1-\\epsilon)^{|S|}$$\n",
    "\n",
    "Now, let's fix c<sub>2</sub>, assume c<sub>2</sub> has true error > ϵ (we do not want it, true error too high). What is the same probability? Also $ Pr_S\\;[c_1\\;is\\;consistent\\;with\\;S] \\le (1-\\epsilon)^{|S|}$.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.12.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "For every c<sub>i</sub> (with error > ϵ): $ Pr_S\\;[c_i\\;is\\;consistent\\;with\\;S] \\le (1-\\epsilon)^{|S|}$.\n",
    "\n",
    "Question: Randomly form S, what is the probability there even exists a function c whose error is > ϵ and is consistent with S?\n",
    "\n",
    "Hint:\n",
    "\n",
    "    Union bound: Given A, B Pr[A ∨ B] ≤ Pr[A] + Pr[B]\n",
    "    *The probability that A or B occurs is less than or equal to the probability that A occurs plus the probability that B occurs*\n",
    "\n",
    "Answer: $Pr[Bad\\;Event] \\le |C|*(1-\\epsilon)^{|S|}$, since there are at most C functions to consider and the probability of failure for each was $(1-\\epsilon)^{|S|}$. Recall, we wanted Pr[Bad Event] < δ, so the goal is \n",
    "\n",
    "$$ Pr[Bad\\;Event] \\le |C|*(1-\\epsilon)^{|S|} \\le \\delta $$\n",
    "\n",
    "The only unknown variable is |S|, so we will solve for it.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.13.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Solving for |S|**\n",
    "\n",
    "$|C|*(1-\\epsilon)^{|S|} \\le \\delta$\\\n",
    "\n",
    "$|C|*(e)^{\\epsilon|S|} \\le \\delta$ (using (1-x) ≈ e<sup>-x</sup>)\\\n",
    "\n",
    "$(e)^{\\epsilon|S|} \\le \\frac{\\delta}{|C|}$\n",
    "\n",
    "$\\epsilon|S| \\le log(\\frac{\\delta}{|C|})$\n",
    "\n",
    "which yields:\n",
    "\n",
    "$$|S| \\ge \\frac{log(\\frac{\\delta}{|C|})}{\\epsilon}$$\n",
    "\n",
    "This is saying that if you choose number of training points larger than $\\frac{log(\\frac{\\delta}{|C|})}{\\epsilon}$, then with probability ≥ (1-δ), the function output c is 1-ϵ accurate.\\\n",
    "\n",
    "Thus we have exactly computed the size of the training set S such that the output function c is 1-ϵ accurate.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.3.14.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Since we assumed A would give a consistent hypothesis each time, that suggests that there is a \"consistent hypothesis\" approach to learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7fd67-696a-40a3-9e6d-00ca9e6ddd04",
   "metadata": {},
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce61fc-115c-4357-a766-7faec52d2284",
   "metadata": {},
   "source": [
    "**[Understanding Machine Learning: From Theory to Algorithms, Chapter 3](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
