{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be158dc-a876-43cb-9c39-279dd11cea45",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41c711-1504-4cd0-93a3-aa8a6963a859",
   "metadata": {},
   "source": [
    "## ***Vocabulary***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ceb54-7137-431e-8ae1-1053d0f2bcbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc47029-8dd1-4934-8f85-9487837b1e2c",
   "metadata": {},
   "source": [
    "# Lecture Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eb618-a347-4dd5-bb64-a4efac8cacf4",
   "metadata": {},
   "source": [
    "## ***Introduction***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2ec31-1e8c-44c3-bb67-c6f2b821879c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We will be looking at how to calculate the true error of a classifier model. \n",
    "\n",
    "Let's assume classification; so the hypothesis h is going to output boolean values (e.g., {0,1}, {-1,1}.\n",
    "\n",
    "- Hold-out approach (validation set) for testing/approximating the true error of a classifier\n",
    "    - Leave some part of the training set out during training time\n",
    "    - Then when you want to evaluate the true error of the classifier, you test the classifier on this held out set.\n",
    "    - The error on the held out set is the approximated true error for unseen data\n",
    " \n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Markov's Inequality**\n",
    "\n",
    "- Let x be a random variable that takes on only positive values\n",
    "- $Pr[x\\ge k*\\mathbf{E}[x]]\\le \\frac{1}{k}$\n",
    "    - *The probability that x is more than a factor of k times the expected value of x, is at most 1 over k*\n",
    " \n",
    "**Chebyshev's Inequality**\n",
    "\n",
    "- Review:\n",
    "    - Let us say $\\mathbf{E}[x]$ = $\\mu$ \n",
    "    - Review the variance of a random variable: $ Var[x] = \\mathbf{E}[(x-\\mathbf{E}[x])^2] $\n",
    "        - On average, how much does a draw of x deviate from its expectation or average squared\n",
    "    - Recall that $\\sqrt{Var[x]} = standard\\;deviation(x) = \\sigma$\n",
    " \n",
    "<br>\n",
    "\n",
    "If we have a random variable, we understand that its mean is $\\mu$, and its variance is $\\sigma$, the probability that the random variable x deviates from its expectation by more than t standard deviations, is less than or equal to one over t<sup>2</sup>.\n",
    "\n",
    "$$ Pr[|x-\\mu| \\gt t*\\sigma] \\le \\frac{1}{t^2} $$\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ed5cd-43a9-4384-be36-0a59ee244e86",
   "metadata": {},
   "source": [
    "## ***Chernoff Bound***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb82a9-1780-4c14-9406-a59c82ba1d90",
   "metadata": {},
   "source": [
    "Let's say we have random variables $x_1, x_2, ..., x_n$, $x_i \\epsilon \\{0,1\\}$ and that $\\mathbf{E}[x_i] = p$ (the chernoff bound holds for $\\mathbf{E}[x_i] = p_i$, but we are fixing to p for simplicity). \n",
    "\n",
    "We also have \n",
    "\n",
    "$$S = \\sum_{i=1}^{n} x_i $$\n",
    "\n",
    "Also let $\\mathbf{E}[S]$ = $\\mu$ = $p*n$, in other words $\\mathbf{E}[x_1+...+x_n] = p*n$\n",
    "\n",
    "The Chernoff Bound says:\n",
    "\n",
    "$$ Pr[S>\\mu +\\delta n] \\le e^{-2n\\delta^2} $$\n",
    "\n",
    "$$ Pr[S<\\mu -\\delta n] \\le e^{-2n\\delta^2} $$\n",
    "\n",
    "$$ \\Rightarrow Pr[|S-\\mu| > \\delta n] \\le 2e^{-2n\\delta^2} $$\n",
    "\n",
    "Basically, when you have a bunch of independent random variables, each ones mean is p and you take the sum of them, you would expect the sum to be about p * n, so this is the expectation of S, the sum. What that Chernoff Bound says is that the probability that your sum S deviates from $\\mu$ is actually exponentially small in the quantity n.\n",
    "\n",
    "\"The probability that I deviate more than $\\delta$n is exponentially small in n, and depending on my choice of $\\delta$ I will be getting different bounds for these probabilities.\" \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.3.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Applying the Chernoff Bound to the case of estimating the true error of a classifier...\n",
    "\n",
    "We have hold-out set S, and we'll say the |S| = n (the size of S is n).\\ \n",
    "Fix h (generated using some independent training set). Recall that there is some underlying distribution D from which we are generating training points, and that S is a sample drawn from D independent of the trianing set.\n",
    "\n",
    "$$ Z = Pr_{x\\textasciitilde D}[h(x) \\ne c(x)] $$\n",
    "\n",
    "where c is the unknown function we are trying to learn, and h is the classifier that we've generated and want to understand its true error, which is Z.\n",
    "\n",
    "What random variable should we define if we want to use the Chernoff Bound...?\n",
    "\n",
    "Let $x_i$ be the random variable that equals 1 if h is incorrect on the i<sup>th</sup> element of S. It will be 0 if h is correct on the i<sup>th</sup> element of S.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "So we have random variables $x_1, x_2, ..., x_n$, and \n",
    "\n",
    "$$ x_i = \\begin{cases} \n",
    "          1\\;if\\;h\\;is\\;correct\\;on\\;i^{th}\\;element \\\\\n",
    "          0\\;otherwise \n",
    "          \\end{cases}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$S = \\sum_{i=1}^{n} x_i $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\mathbf{E}[S] = n*p $$\n",
    "\n",
    "where p is actually the true error of h, because p is the expected value of $x_i$, and $x_i$ outputs 1 when incorrect.\n",
    "\n",
    "$$ Pr[|S - n*p| > \\delta n] \\le 2e^{-2n\\delta^2} $$\n",
    "\n",
    "(Recall p is the true error of classifier h)  \n",
    "\n",
    "Say we set $\\delta$ = .1, then $ Pr[|S - n*p| > .1n] \\le 2e^{\\frac{-2n}{100}}$ \n",
    "\n",
    "I will call the quantity $ 2e^{\\frac{-2n}{100}} $ from the above inequality the confidence parameter. \n",
    "\n",
    "How large do we need to take n before the confidence parameter becomes smaller than some small quantity $\\alpha$? \n",
    "\n",
    "$$ 2e^{\\frac{-2n}{100}} \\lt \\alpha $$\n",
    "$$ e^{\\frac{-2n}{100}} \\lt \\frac{\\alpha}{2} $$\n",
    "$$ \\frac{-2n}{100} \\lt log(\\frac{\\alpha}{2}) \\Rightarrow n \\gt 50*log(\\frac{2}{\\alpha})$$ \n",
    "\n",
    "So if we want the probability of failure to be less than alpha, and we want to be confident that our estimate is within .1\\*n, then we need n to be $ 50*log(\\frac{2}{\\alpha}) $\n",
    "\n",
    "Notice: if $ |S-n*p| \\le .1n \\Rightarrow error\\;rate\\;on\\;S\\;is\\;within\\;.1\\;of\\;true\\;error\\;rate $\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eefce1-6926-4e40-bb51-c850c23f3208",
   "metadata": {},
   "source": [
    "## ***How It Works***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47367318-9c44-41f9-acd7-2a9cdf4fb012",
   "metadata": {},
   "source": [
    "The hold-out set is somewhat expensive..\n",
    "- Data is expensive or difficult to obtain, and we arent using it for training the classifier\n",
    "- If we want to try out multiple methods for generating classifiers, we quickly lose confidence in our estimates (however many times you use the hold out set you must multiply alpha). This gets expensive when testing different classifiers and parameter settings.\n",
    "\n",
    "How can we build lots of understand the true error of many different classifiers that we generate? How can we reuse our training set to build different classifiers and still understand our true error? Still an open problem in the field, but best current solution is cross-validation.\n",
    "\n",
    "Cross-validation works very well in practice, and is used in packages such as scikit-learn. \n",
    "\n",
    "---\n",
    "\n",
    "The idea behind cross validation is that we are going to take our entire training set and break it up into *folds*. We will then use the training set to at the same time train the classifier and calculate the true error.\n",
    "\n",
    "First we'll hold out fold 1 and train using folds 2 thorugh fold k. We will then test on fold 1, and that will be our estimate for that classifiers true error.\n",
    "\n",
    "Then, we'll hold out fold 2 and train using fold 1 and fold 3 through fold k. We will the test on fold 2, and that will be our estimate for the true estimate for that classifier. \n",
    "\n",
    "We will do this k times, once for each fold, and we will average all the errors that we got. That will be the estimate for the true error of a classifer produced with the parameters used to build the model.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.6.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Let's use decision trees for an example. We have a training set S, and are trying to decide:\n",
    "- Should I build a decision tree of depth 10 or depth 15?\n",
    "\n",
    "We decide using cross-validation...\n",
    "\n",
    "We create the folds in our training set and set depth = 10. We leave out fold 1 and build a decision tree with depth 10, and test the accuracy on fold 1. Then we'll hold out fold 2 and do the same thing. We will repeat for all folds and take the average of their error rates, which will provide and estimate of the true error for the decision tree of depth 10.\n",
    "\n",
    "Then, we will do the exact same thing, but set the depth parameter to 15 this time. We will end up with the estimate for the true error for the tree with depth 15. \n",
    "\n",
    "Whichever error is smaller would be the tree we want to use!\n",
    "\n",
    "---\n",
    "\n",
    "Question: What should k be set to?\n",
    "- Between 5 and 10 is typically what is used.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.5.7.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc478fde-bbf2-433e-af53-7f2f12ee47fd",
   "metadata": {},
   "source": [
    "## ***Resources***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093a1bd-6d19-4c1c-b80f-ce2b3af34b9a",
   "metadata": {},
   "source": [
    "**[Understanding Machine Learning: From Theory to Algorithms, Chapter 3](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)** (Internet link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7fd67-696a-40a3-9e6d-00ca9e6ddd04",
   "metadata": {},
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce61fc-115c-4357-a766-7faec52d2284",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
