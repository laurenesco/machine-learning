{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db1a21a-ad14-4c0a-8d8d-9e5cfe39ea04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1.8 Gradient Descent #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca428ac-94b9-4bb0-aa8d-e3699c2f69f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ***Vocabulary & Code*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f24a6-ade1-474a-8472-d1bf7a98b87d",
   "metadata": {},
   "source": [
    "**Convexity**:\n",
    "- A function is convex if the chord connecting any 2 points of the graph lies above the function.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.8.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51075cc6-4aa0-4897-a75f-eb4f7e856945",
   "metadata": {},
   "source": [
    "# Lecture Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da80c3-2803-4ea7-8b5d-6b10bcf234a2",
   "metadata": {},
   "source": [
    "## ***1.8.0 Introduction*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb30702-7d9c-4bcd-8583-fbf1c4c78ae9",
   "metadata": {},
   "source": [
    "Goal: Find minimizer of a function.\n",
    "\n",
    "We can evaluate $f(x)$ at some point $x$, and also evaluate the derivative ,$f'(x)$, to find the slope of the tangent line at that point..\n",
    "\n",
    "**Update Rule:**\n",
    "- If $f'(x) < 0$, move a bit to the right\n",
    "- Else if $f'(x) > 0$, move a bit to the left\n",
    "- Else if $f'(x) = 0$ or is close to 0, then stop and ouput $x$.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.8.1.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "What about a more complicated function? Using the same update rule, how can we reach the global minimum instead of the local minimum?\n",
    "\n",
    "If the function is convex, we will always reach the global minimum.\n",
    "\n",
    "---\n",
    "\n",
    "Another example: $f(x) = w^Tx + b$ (linear functions in $d$ dimensions). We are currently at point $x$, we want to know what direction to move in to minimize $f$. By \"direction\" we mean a unit vector. $$\n",
    "\n",
    "$f(x + u)$, where $u$ is some arbitraty unit vector.\n",
    "\n",
    "$$f(x+u) = w^Tx+w^Tu+b$$\n",
    "\n",
    "The correct choice of $u$ is $\\frac{-w}{||w||}$.\n",
    "\n",
    "The way to maximize the value of the inner product for the unit vector ($w^Tu$) would be to choose $\\frac{w}{||w||}$, and since we want to minimize we will use $\\frac{-w}{||w||}$.\n",
    "\n",
    "Also, if we move in direction $\\frac{-w}{||w||}$, then $f$ decreases by $||w||_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1330bf-01ce-4031-a044-862bbdf636e2",
   "metadata": {},
   "source": [
    "## ***1.8.1 Putting it Together*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c48990-bcb4-41da-909f-216b461753f2",
   "metadata": {},
   "source": [
    "Thus far, our idea has been to look at tangent lines and this idea works for linear functions and simple complex functions.\n",
    "\n",
    "Even if we want to minimize more complicated functions, assume they are \"locally\" linear.\n",
    "\n",
    "$f$ at point $x$ can be Taylor expanded: \n",
    "$$f(x+\\epsilon) = f(x) + \\epsilon*f'(x)+ \\frac{\\epsilon^2}{2!} f''(x)+\\frac{\\epsilon^3}{3!} f'''(x)+.....$$\n",
    "The above is an expression in terms of $\\epsilon$. The first term is a linear function of $\\epsilon$, and when $\\epsilon$ is small, the rest of the terms are negligible. This means that when we are looking at very small neighborhoods, or values of $\\epsilon$, $f$ actually is a linear function. \n",
    "\n",
    "---\n",
    "\n",
    "Taylor's theorem also holds in $d$ dimensions, meaning even in $d$ dimensions, the function will look linear in a small enough neighborhood. Instead of taking derivatives, in higher dimensions, we must look at gradients.\n",
    "\n",
    "The gradient of $f$ at point $x$ is written:\n",
    "\n",
    "$$\\nabla f(x)=(\\frac{\\partial f}{\\partial x_1}(x), ... , \\frac{\\partial f}{\\partial x_d}(x)) $$\n",
    "\n",
    "Which is a $d$-dimensional vector.\n",
    "\n",
    "---\n",
    "\n",
    "Example:\n",
    "\n",
    "$$f = w^Tx+b \\leadsto \\frac{\\partial f}{\\partial x_i} = w_i \\leadsto \\nabla f*w $$\n",
    "\n",
    "Another Example:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.8.2.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae1a6b-937a-4403-a19f-658ba557064f",
   "metadata": {},
   "source": [
    "## ***1.8.2 Defining and Applying*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ccb2e-59c1-4575-bc1b-a762c5bfedd4",
   "metadata": {},
   "source": [
    "Define Gradient Descent:\n",
    "\n",
    "Imagine we are trying to minimize $f(w)$. Initially we'll choose $w$ randomly, some arbitraty starting value. \n",
    "\n",
    "If $||\\nabla f(w)||_2 \\lt \\epsilon$, stop and output $w$.\\\n",
    "Otherwise, $w_{new} = w_{old} - \\eta \\nabla f(w_{old})$, where $\\eta$ is the step-size parameter.\n",
    "\n",
    "This is also written as $w_j^{new} = w_j^{old} - \\eta \\frac{\\partial f}{\\partial w_j}(w_{old})$. \n",
    "\n",
    "The step-size parameter is usually set to be relatively small, because the linearity of these complicated functions only holds locally.\n",
    "\n",
    "---\n",
    "\n",
    "Let's apply GD to linear regression.\n",
    "\n",
    "In linear regression, we have a training set $S$ of size $m$. \\\n",
    "We are searching for this function: $h(x) = w^Tx+b$, and our function of loss was MSE (mean squared error): $M.S.E.(w) = \\frac{1}{m}\\sum_{j=1}^m(w^Tx^j+b-y^j)^2$. \n",
    "\n",
    "We are trying to minimize the MSE, so that is what we will use GD on, that will be our $f$. GD is used on loss.\n",
    "\n",
    "We will call $w^Tx^j+b-y^j$ from inside $f$ $g_j$. We need to compute the gradient of the MSE at the point $w$, so our first step should be to compute the partial derivative $g_j$ w.r.t. $w_i$. \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.8.4.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "In this case, the update rule is:\n",
    "\n",
    "$$ w_{new} = w_{old} - \\eta \\nabla MSE(w) $$\n",
    "\n",
    "It is important to note that MSE is a convex function. And the running time for computing this notation is $\\mathcal{O}(m*n)$. This function is also easily parallelizable. We can send each of the $j$'s to a different processor.\n",
    "\n",
    "---\n",
    "\n",
    "**Stochastic Gradient Descent**\n",
    "\n",
    "Previously in the linear regression example, we summed over all points in the training set. \n",
    "\n",
    "We can choose an index $j$ at random and compute the gradient with respect to this point only...\n",
    "\n",
    "The new update rule for MSE would be:\n",
    "\n",
    "$$ w_{new} = w_{old} - 2\\eta (w^Tx^j+b-y^j)x^j$$\n",
    "\n",
    "Question: Why does this make sense as an update rule?\n",
    "- In expectation, our update will use the entire gradient because each point will be chosen with equal probability.\n",
    "- $\\mathbf{E}[w_{new}] = w_{old} -2 \\eta*\\frac{1}{m}\\sum_{j=1}^m(w^Tx^j+b-y^j)x^j$\n",
    "\n",
    "---\n",
    "\n",
    "**Batches** can be used to interpolate between gradient descent and and pure stochastic gradient descent. Batches will reduce the variance of the random variable corresponding to the weight vectors that you are obtaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b06237-2a5a-4553-9561-541d3ea829ab",
   "metadata": {},
   "source": [
    "## ***1.8.3 Choosing Step Size*** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf6e76-7593-4469-bc30-5dde65549bfc",
   "metadata": {},
   "source": [
    "Question: How do we choose $\\eta$, the step-size?\n",
    "- More art than science\n",
    "- Use cross-validation to pick $\\eta$\n",
    "- Many techniques for adaptively choosing $\\eta$ that are very successful\n",
    "- **Momentum**:\n",
    "    - Has a \"velocity\" variable $v$, which is initially 0.\n",
    "    - $V_i = \\alpha*V_{i-1}-\\eta g_i$, where $g_i$ is the gradient at point $i$.\n",
    "    - This takes a weighted average of $\\eta g_i$'s.\n",
    "    - $w_{new} = w_{old} + V_i$\n",
    " \n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"images/1.8.5.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Accelerated Gradient Descent**\n",
    "Will be studied in optimization classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c23e04-403f-4751-97a0-a6211280528e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Personal Notes #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ede413-b76e-464f-9d1b-1af15b60f457",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summary of GD Process:\n",
    "\n",
    "1. If $||\\nabla f(w)||_2 \\lt \\epsilon$, stop and output $w$.\\\n",
    "2. Otherwise, $w_{new} = w_{old} - \\eta \\nabla f(w_{old})$, where $\\eta$ is the step-size parameter. This is also written as $w_j^{new} = w_j^{old} - \\eta \\frac{\\partial f}{\\partial w_j}(w_{old})$. \n",
    "\n",
    "- **Solve the loss function**: Compute the loss function value (e.g., hinge loss, squared loss) for a data point xixiâ€‹.\n",
    "- **Take the derivative**: Compute the gradient of the loss function with respect to the model parameters (e.g., w).\n",
    "- **Plug into the update rule**: Update the model parameters using the gradient in the SGD update rule.\n",
    "\n",
    "This iterative process continues until the model converges or a stopping criterion is met.\n",
    "\n",
    "Note: $||\\nabla f(w)||_2 = \\sqrt{w_1^2 + w_2^2 + ... + w_n^2}$\n",
    "\n",
    "---\n",
    "\n",
    "### Generalized Gradient Descent (GD) Update Rule:\n",
    "\n",
    "For **Gradient Descent (GD)**, the update rule is derived from minimizing a loss function $L(w)$ over the entire dataset. The generalized form is:\n",
    "\n",
    "$$\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\nabla L(w_{\\text{old}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w_{\\text{new}}$ is the updated weight vector.\n",
    "- $w_{\\text{old}}$ is the current weight vector.\n",
    "- $\\eta$ is the learning rate (step size).\n",
    "- $\\nabla L(w_{\\text{old}})$ is the **gradient of the loss function** with respect to $w$, computed using **all the data points** in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Generalized Stochastic Gradient Descent (SGD) Update Rule:\n",
    "\n",
    "For **Stochastic Gradient Descent (SGD)**, the gradient is computed using only **one random data point** (or a small batch of data) instead of the entire dataset. The generalized form of the SGD update rule is:\n",
    "\n",
    "$$\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\nabla L_i(w_{\\text{old}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w_{\\text{new}}$ and $w_{\\text{old}}$ are the updated and current weight vectors.\n",
    "- $\\eta$ is the learning rate.\n",
    "- $\\nabla L_i(w_{\\text{old}})$ is the gradient of the loss function with respect to $w$, but evaluated only on a **single data point** (or a mini-batch) $i$.\n",
    "\n",
    "---\n",
    "\n",
    "### Differences Between GD and SGD:\n",
    "\n",
    "1. **Full Gradient vs. Stochastic Gradient**:\n",
    "   - **GD** computes the gradient $\\nabla L(w)$ using all training examples, which is computationally expensive for large datasets.\n",
    "   - **SGD** computes the gradient using a **single random data point** (or a small batch), which makes it much faster per iteration but introduces some noise due to the randomness.\n",
    "\n",
    "2. **Convergence**:\n",
    "   - **GD** moves more smoothly towards the minimum since it uses the full dataset to compute the gradient at each step.\n",
    "   - **SGD** introduces more variability in updates, which can help avoid local minima but may require more iterations to converge.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Update Rules:\n",
    "\n",
    "- **GD Update Rule**:\n",
    "  $$\n",
    "  w_{\\text{new}} = w_{\\text{old}} - \\eta \\nabla L(w_{\\text{old}})\n",
    "  $$\n",
    "  (Gradient computed over the **entire dataset**)\n",
    "\n",
    "- **SGD Update Rule**:\n",
    "  $$\n",
    "  w_{\\text{new}} = w_{\\text{old}} - \\eta \\nabla L_i(w_{\\text{old}})\n",
    "  $$\n",
    "  (Gradient computed over a **single data point** $i$ or mini-batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
