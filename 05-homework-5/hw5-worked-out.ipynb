{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58c0595-dc34-4964-8237-b1cb1e3390d8",
   "metadata": {},
   "source": [
    "# Problem 1: Gaussian Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f227285-49d0-4dd7-a843-6c37cef95e74",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Are $X_3$ and $X_4$ correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbb7cc-a496-4be7-9211-fe9e9210adc9",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "Since the entry of $\\sum_{34} = 0$, we can conclude that $X_3$ and $X_4$ have 0 covariance, and are thus **not correlated**.\n",
    "\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "0.71 & -0.43 & 0.43 & 0 \\\\\n",
    "-0.43 & 0.46 & -0.26 & 0 \\\\\n",
    "0.43 & -0.26 & 0.46 & 0 \\\\\n",
    "0 & 0 & 0 & 0.2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8b6ac-24b0-4d82-a895-425542a54ca4",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f61d2-04ba-4b48-8b1c-2ad38c0e34e8",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "Using the precision matrix $Q$ to verify the conditional dependence of $X_1$ and $X_2$, we can see that $Q_{34} = 0$. This indicates that $X_1$ and $X_2$ are **conditionally independent** given $X_1$ and $X_2$.\n",
    "\n",
    "Thus, we can conclude that $Cov(X_3, X_4 \\mid X_1, X_2) = 0$.\n",
    "\n",
    "$$\n",
    "Q = \n",
    "\\begin{bmatrix}\n",
    "5 & 3 & -3 & 0 \\\\\n",
    "3 & 5 & 0 & 0 \\\\\n",
    "-3 & 0 & 5 & 0 \\\\\n",
    "0 & 0 & 0 & 5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f39954-83fb-4343-8569-3f5b904ab3b8",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Please find the Markov blanket of $X_2$. Recall that the Markov blanket of $X_i$\n",
    "is the set of variables (denoted by $X_{M_i}$ ), such that\n",
    "$$X_i ⊥ X_{¬\\{i\\}∪M_i} | X_{M_i}$$\n",
    "where $$¬\\{i\\} ∪ M_i$$ denotes all the variables outside of $\\{i\\} ∪ M_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39beb8f2-430d-47b6-bb8e-4b6c87244420",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "Using the precision matrix, $Q$, we can find the Markov blanket by finding the minimal set of variables needed to make $X_2$ conditionally indpendent of the other variables.\n",
    "\n",
    "Given \n",
    "\n",
    "$$\n",
    "Q = \n",
    "\\begin{bmatrix}\n",
    "5 & 3 & -3 & 0 \\\\\n",
    "3 & 5 & 0 & 0 \\\\\n",
    "-3 & 0 & 5 & 0 \\\\\n",
    "0 & 0 & 0 & 5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Since we are interested in $X_2$, we will evaluate the second row of $Q$, $[3,5,0,0]$.\n",
    "\n",
    "- $Q_{21} = 3$, so $X_2$ is conditionally dependent on $X_1$.\n",
    "- $Q_{23}$ and $Q_{24}$ both equal 0, so $X_2$ is conditionally independent of $X_3$ and $X_4$.\n",
    "\n",
    "Thus, **the Markov blanket for $X_2$ is:**\n",
    "\n",
    "$$ X_{M_2} = \\{X_1\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e3976-891d-4682-a570-4eb35c66e334",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (d)\n",
    "\n",
    "Assume that $Y = [Y_1, Y_2]^⊤$ is defined by\n",
    "$$Y_1 = X_1 + X_4$$ \n",
    "$$Y_2 = X_2 − X_4$$\n",
    "Please calculate the covariance matrix of $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2da752-de2f-4bd9-b525-000ad81cedb7",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "\n",
    "Let us fix some matrix $A$, which is the transformation matrix that maps $X$ to $Y$:\n",
    "\n",
    "$$ Y = AX$$\n",
    "\n",
    "Deriving $A$:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} Y_1 \\\\ Y_2 \\end{bmatrix} = \\begin{bmatrix} X_1 + X_4 \\\\ X_2 - X_4 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y = \\begin{bmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix} \\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ X_4 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now that we have $A$, the transformation matrix, we can use the relationship between $\\Sigma$, $X$, and $Y$ to find $Cov(Y)$. Since $Y$ is a linear transformation of $X$ by $Y = AX$, then:\n",
    "\n",
    "$$ Cov(Y) = A\\Sigma A^\\top$$\n",
    "\n",
    "---\n",
    "\n",
    "We will need to calculate $A\\Sigma A^\\top$:\n",
    "\n",
    "$$\n",
    "A \\Sigma A^\\top = \\begin{bmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "0.71 & -0.43 & 0.43 & 0 \\\\ \n",
    "-0.43 & 0.46 & -0.26 & 0 \\\\ \n",
    "0.43 & -0.26 & 0.46 & 0 \\\\ \n",
    "0 & 0 & 0 & 0.2 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\\\ 1 & -1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Which comes out to:\n",
    "\n",
    "$$\n",
    "\\operatorname{Cov}(Y) = A \\Sigma A^\\top = \\begin{bmatrix} 0.91 & -0.63 \\\\ -0.63 & 0.66 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ef8e3-22c3-4258-b503-4980c527c6ca",
   "metadata": {},
   "source": [
    "# Problem 2: Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a87b2a-5bae-4f7b-909b-547e22ab76a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "Assume we run EM starting from an initialization of $\\mu_1 = −2$ and $\\mu_2 = 2$.\n",
    "Please decide the value of $\\mu_1$ and $\\mu_2$ at the next iteration of EM algorithm. (You may\n",
    "find it handy to know that $\\frac{1}{1 + exp(−4)} \\approx 0.98)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb612eaf-5d64-41a1-8103-589b79d90e1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Solution**\n",
    "\n",
    "Given: $x^1 = -1$, $x^2 = 1$, $\\frac{1}{1 + exp(−4)} \\approx 0.98)$, $\\mu_1 = -2$, and $\\mu_2 = 2$.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 0: Initialize the unknown parameters**\n",
    "\n",
    "Already done. $\\mu_1 = -2$ and $\\mu_2 = 2$ is given.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Calculate the posterior distribution**\n",
    "\n",
    "Let's fix $\\gamma_{ik}^t =  Pr(z_i=k\\mid x_i, \\theta_t)$, the posterior distribution at iteration $t$.\n",
    "\n",
    "Then, for the **first data point**:\n",
    "\n",
    "$$ \\gamma_{11} = Pr(z_i =1 \\mid x_i, \\theta_t) $$\n",
    "\n",
    "$$ = \\frac{\\pi_1 \\mathcal{N}(x^1\\mid \\mu_1, 1)}{\\pi_1 \\mathcal{N}(x^1\\mid \\mu_1, 1) + \\pi_2 \\mathcal{N}(x^1\\mid \\mu_2, 1)} $$\n",
    "\n",
    "Substituting in the given values:\n",
    "\n",
    "$$ = \\frac{\\pi_1 \\frac{1}{\\sqrt{2\\pi}} exp(-\\frac{(-1+2)^2}{2})}\n",
    "{\\pi_1 \\frac{1}{\\sqrt{2\\pi}} exp(-\\frac{(-1+2)^2}{2}) + \n",
    "\\frac{1}{\\sqrt{2\\pi}} exp(-\\frac{(-1-2)^2}{2})} $$\n",
    "\n",
    "Simplifying:\n",
    "\n",
    "$$ = \\frac{exp(-\\frac{1}{2})}{exp(-\\frac{1}{2}) + exp(-\\frac{9}{2})} $$\n",
    "\n",
    "Using the given $\\frac{1}{1 + exp(-4)} \\approx 0.98)$:\n",
    "\n",
    "$$ \\gamma_{11} \\approx 0.98 $$\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$ \\gamma_{12} \\approx 0.02 $$\n",
    "\n",
    "And for the **second data point**:\n",
    "\n",
    "$$ \\gamma_{21} = Pr(z_i = 1 \\mid x_i, \\theta_t) $$\n",
    "\n",
    "$$ = \\frac{\\pi_1 \\mathcal{N}(x^2\\mid \\mu_1, 1)}\n",
    "{\\pi_1 \\mathcal{N}(x^2\\mid \\mu_1, 1) + \n",
    "\\pi_2 \\mathcal{N}(x^2\\mid \\mu_2, 1)} $$\n",
    "\n",
    "Substituting in the given values:\n",
    "\n",
    "$$ = \\frac{\\pi_1 \\frac{1}{\\sqrt{2\\pi}} exp(-\\frac{(1+2)^2}{2})}\n",
    "{\\pi_1 \\frac{1}{\\sqrt{2\\pi}} exp(-\\frac{(1+2)^2}{2}) + \n",
    "\\frac{1}{\\sqrt{2\\pi}} exp(-\\frac{(1-2)^2}{2})} $$\n",
    "\n",
    "Simplifying:\n",
    "\n",
    "$$ = \\frac{exp(-\\frac{9}{2})}\n",
    "{exp(-\\frac{9}{2}) + \n",
    "exp(-\\frac{1}{2})} $$\n",
    "\n",
    "Solving:\n",
    "\n",
    "$$ \\gamma_{21} \\approx 0.02 $$\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$ \\gamma_{22} \\approx 0.98 $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Maximize the Likelihood Function**\n",
    "\n",
    "Using the update rule for $\\mu$ derived in Lecture 4.2.0: \n",
    "\n",
    "$$\\mu_k^{t+1} = \\frac{\\sum_{i=1}^n \\gamma_{ik}^t x_i}{\\sum_{i=1}^n \\gamma_{ik}^t} $$\n",
    "\n",
    "We have:\n",
    "\n",
    "$$ \\mu_1^{t+1} = \\frac{(.98\\cdot -1)+(.02\\cdot 1)}{.98+.02} = frac{-.98+.02}{1}= -.96$$\n",
    "$$ \\mu_2^{t+1} = \\frac{(.02\\cdot -1)+(.98\\cdot 1)}{.02+.98} = frac{-.02+.98}{1}= .96$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a52245-0c02-456a-9752-bd31783ba2c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "\n",
    "Do you think EM (when initialized with $\\mu_1 = −2$ and $\\mu_2 = 2$) will eventually\n",
    "converge to $\\mu_1 = −1$ and $\\mu_2 = 1$(i.e., coinciding with the two data points). Please justify your answer using either your theoretical understanding or the result of an empirical\n",
    "simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950530a-1b4f-4f41-9517-7146e4421cac",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "\n",
    "I think the EM algorithm **will** eventually converge to $\\mu_1 = −1$ and $\\mu_2 = 1$, coinciding with the two data points. Here is my reasoning:\n",
    "\n",
    "There are exactly two points and exactly two distributions, with the distributions having different means ($\\mu$). This means that the distributions are **not** identical. Thus, naturally each point will coincide precisely with a distribution. Furthermore, the symmetry of the model, including the means and the data points, around 0 suggests that the model will converge nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bdd8a9-6833-40f3-b874-473a784eef64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "\n",
    "Please decide the fixed point of EM when we initialize it from $\\mu_1 = \\mu_2 = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad912fec-372b-42aa-b600-b079e10c7059",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "\n",
    "With $\\mu_1 = \\mu_2$ both initialized to 2, and $\\gamma_{ik}^t =  Pr(z_i=k\\mid x_i, \\theta_t)$. The steps of EM will be as follows:\n",
    "\n",
    "**Step 1: Calculate the posterior distribution**\n",
    "\n",
    "Since the means are equal, we can assume that:\n",
    "\n",
    "$$ \\gamma_{i1} = \\gamma_{i2} = .5 $$\n",
    "\n",
    "This is because the likelihood for each point will be the same, since the distributions are initialized to be identical.\n",
    "\n",
    "**Step 2: Maximize the Likelihood Function**\n",
    "\n",
    "Using the update rule for $\\mu$ derived in Lecture 4.2.0: \n",
    "\n",
    "$$\\mu_k^{t+1} = \\frac{\\sum_{i=1}^n \\gamma_{ik}^t x_i}{\\sum_{i=1}^n \\gamma_{ik}^t} $$\n",
    "\n",
    "We have:\n",
    "\n",
    "$$ \\mu_1 = \\frac{.5\\cdot (-1)+.5\\cdot 1}{.5+.5} = 0 $$\n",
    "\n",
    "and:\n",
    "\n",
    "$$ \\mu_2 = \\frac{.5\\cdot (-1)+.5\\cdot 1}{.5+.5} = 0 $$\n",
    "\n",
    "And since they are again identical, this cycle will repeat. Thus, **the fixed point for $\\mu_1$ and $\\mu_2$ is 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e50ebd-18f1-4432-83de-7f7506f95011",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (d)\n",
    "\n",
    "Please decide the fixed point of K-means when we initialize it from $\\mu_1 = −2$ and $\\mu_2 = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66148e57-608d-46a0-ae0b-288392729308",
   "metadata": {},
   "source": [
    "#### **Solution**\n",
    "\n",
    "Given that $x_1 = -1$, $x_2 = 1$, $\\mu_1 = −2$ and $\\mu_2 = 2$ for a K-means problem I have worked out the steps of the K-means algorithm below.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img width=\"60%\" src=\"2d.png\" alt=\"Professor Notes\" />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "As we can see, after 1 iteration the algorithm converges and reaches **the fixed point of $\\mu_1 = -1$ and $\\mu_2 = 1$**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
